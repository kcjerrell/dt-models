{
  "lastUpdate": 1766636886690,
  "officialModels": [
    {
      "name": "AuraFlow v0.1",
      "file": "auraflow_v0.1_q8p.ckpt",
      "prefix": "",
      "version": "auraflow",
      "defaultScale": 16,
      "textEncoder": "pile_t5_xl_encoder_q8p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "deprecated": true
    },
    {
      "name": "AuraFlow v0.1 (8-bit)",
      "file": "auraflow_v0.1_q5p.ckpt",
      "prefix": "",
      "version": "auraflow",
      "defaultScale": 16,
      "textEncoder": "pile_t5_xl_encoder_q8p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "deprecated": true
    },
    {
      "name": "AuraFlow v0.2",
      "file": "auraflow_v0.2_q8p.ckpt",
      "prefix": "",
      "version": "auraflow",
      "defaultScale": 16,
      "textEncoder": "pile_t5_xl_encoder_q8p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "name": "AuraFlow v0.2 (8-bit)",
      "file": "auraflow_v0.2_q5p.ckpt",
      "prefix": "",
      "version": "auraflow",
      "defaultScale": 16,
      "textEncoder": "pile_t5_xl_encoder_q8p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "name": "FLUX.1 [schnell]",
      "file": "flux_1_schnell_q8p.ckpt",
      "prefix": "",
      "version": "flux1",
      "defaultScale": 16,
      "textEncoder": "t5_xxl_encoder_q6p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt",
      "highPrecisionAutoencoder": true,
      "isConsistencyModel": true,
      "paddedTextEncodingLength": 256,
      "hiresFixScale": 24
    },
    {
      "name": "FLUX.1 [schnell] (5-bit)",
      "file": "flux_1_schnell_q5p.ckpt",
      "prefix": "",
      "version": "flux1",
      "defaultScale": 16,
      "textEncoder": "t5_xxl_encoder_q6p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt",
      "highPrecisionAutoencoder": true,
      "isConsistencyModel": true,
      "paddedTextEncodingLength": 256,
      "hiresFixScale": 24
    },
    {
      "name": "Fooocus Inpaint SDXL v2.6",
      "file": "fooocus_inpaint_sd_xl_v2.6_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "inpainting",
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Fooocus Inpaint SDXL v2.6 (8-bit)",
      "file": "fooocus_inpaint_sd_xl_v2.6_q6p_q8p.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "inpainting",
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "HiDream E1 [full]",
      "file": "hidream_e1_full_q8p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 12,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "modifier": "editing",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-E1 [full]](https://huggingface.co/HiDream-ai/HiDream-E1-Full) is an image editing model built on HiDream-I1. It is MIT-licensed and commercially friendly. Trained at 768×768 resolution using a Flow Matching objective, the model performs best with trailing samplers and 30–50 sampling steps. For optimal results, ensure the width is set to 768 and use the following prompt format: Editing Instruction: {}. Target Image Description: {}."
    },
    {
      "name": "HiDream E1 [full] (5-bit)",
      "file": "hidream_e1_full_q5p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 12,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "modifier": "editing",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-E1 [full]](https://huggingface.co/HiDream-ai/HiDream-E1-Full) is an image editing model built on HiDream-I1. It is MIT-licensed and commercially friendly. Trained at 768×768 resolution using a Flow Matching objective, the model performs best with trailing samplers and 30–50 sampling steps. For optimal results, ensure the width is set to 768 and use the following prompt format: Editing Instruction: {}. Target Image Description: {}."
    },
    {
      "name": "HiDream E1-1",
      "file": "hidream_e1_1_q8p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "modifier": "editing",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-E1-1](https://huggingface.co/HiDream-ai/HiDream-E1-1) is an image editing model built on HiDream-I1. It is MIT-licensed and commercially friendly. Trained with dynamic resolutions (around 1MP) using a Flow Matching objective, the model performs best with trailing samplers and 30–50 sampling steps."
    },
    {
      "name": "HiDream E1-1 (5-bit)",
      "file": "hidream_e1_1_q5p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "modifier": "editing",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-E1-1](https://huggingface.co/HiDream-ai/HiDream-E1-1) is an image editing model built on HiDream-I1. It is MIT-licensed and commercially friendly. Trained with dynamic resolutions (around 1MP) using a Flow Matching objective, the model performs best with trailing samplers and 30–50 sampling steps."
    },
    {
      "name": "HiDream I1 [dev]",
      "file": "hidream_i1_dev_q8p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "guidanceEmbed": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-I1 [dev]](https://huggingface.co/HiDream-ai/HiDream-I1-Dev) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 20–30 sampling steps recommended. Text guidance is not effective for this model."
    },
    {
      "name": "HiDream I1 [dev] (5-bit)",
      "file": "hidream_i1_dev_q5p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "guidanceEmbed": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-I1 [dev]](https://huggingface.co/HiDream-ai/HiDream-I1-Dev) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 20–30 sampling steps recommended. Text guidance is not effective for this model."
    },
    {
      "name": "HiDream I1 [fast]",
      "file": "hidream_i1_fast_q8p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "isConsistencyModel": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-I1 [fast]](https://huggingface.co/HiDream-ai/HiDream-I1-Fast) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 10–20 sampling steps recommended. Text guidance is not effective for this model."
    },
    {
      "name": "HiDream I1 [fast] (5-bit)",
      "file": "hidream_i1_fast_q5p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "isConsistencyModel": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-I1 [fast]](https://huggingface.co/HiDream-ai/HiDream-I1-Fast) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 10–20 sampling steps recommended. Text guidance is not effective for this model."
    },
    {
      "name": "HiDream I1 [full]",
      "file": "hidream_i1_full_q8p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-I1 [full]](https://huggingface.co/HiDream-ai/HiDream-I1-Full) is a state-of-the-art open-source image generation model known for its exceptional prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended."
    },
    {
      "name": "HiDream I1 [full] (5-bit)",
      "file": "hidream_i1_full_q5p.ckpt",
      "prefix": "",
      "version": "hidream_i1",
      "defaultScale": 16,
      "textEncoder": "llama_3.1_8b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clipEncoder": "long_clip_vit_l14_f16.ckpt",
      "additionalClipEncoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "t5Encoder": "t5_xxl_encoder_q6p.ckpt",
      "highPrecisionAutoencoder": true,
      "paddedTextEncodingLength": 128,
      "hiresFixScale": 24,
      "note": "[HiDream-I1 [full]](https://huggingface.co/HiDream-ai/HiDream-I1-Full) is a state-of-the-art open-source image generation model known for its exceptional prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended."
    },
    {
      "name": "Instruct Pix2Pix",
      "file": "instruct_pix2pix_22000_f16.ckpt",
      "prefix": "",
      "version": "v1",
      "defaultScale": 8,
      "modifier": "editing",
      "deprecated": true
    },
    {
      "name": "Kandinsky v2.1",
      "file": "kandinsky_f16.ckpt",
      "prefix": "",
      "version": "kandinsky2.1",
      "upcastAttention": false,
      "defaultScale": 12,
      "textEncoder": "xlm_roberta_f16.ckpt",
      "autoencoder": "kandinsky_movq_f16.ckpt",
      "deprecated": true,
      "imageEncoder": "image_vit_l14_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt",
      "diffusionMapping": "kandinsky_diffusion_mapping_f16.ckpt"
    },
    {
      "name": "MiniSD v1.4",
      "file": "minisd_v1.4_f16.ckpt",
      "prefix": "",
      "version": "v1",
      "defaultScale": 4,
      "deprecated": true
    },
    {
      "name": "PixArt Sigma XL 1K",
      "file": "pixart_sigma_xl_2_1024_ms_f16.ckpt",
      "prefix": "",
      "version": "pixart",
      "defaultScale": 16,
      "textEncoder": "t5_xxl_encoder_q6p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "name": "PixArt Sigma XL 1K (8-bit)",
      "file": "pixart_sigma_xl_2_1024_ms_q8p.ckpt",
      "prefix": "",
      "version": "pixart",
      "defaultScale": 16,
      "textEncoder": "t5_xxl_encoder_q6p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "name": "PixArt Sigma XL 512",
      "file": "pixart_sigma_xl_2_512_ms_f16.ckpt",
      "prefix": "",
      "version": "pixart",
      "defaultScale": 8,
      "textEncoder": "t5_xxl_encoder_q6p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "name": "PixArt Sigma XL 512 (8-bit)",
      "file": "pixart_sigma_xl_2_512_ms_q8p.ckpt",
      "prefix": "",
      "version": "pixart",
      "defaultScale": 8,
      "textEncoder": "t5_xxl_encoder_q6p.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "name": "Qwen Image 1.0",
      "file": "qwen_image_1.0_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image 1.0 (6-bit)",
      "file": "qwen_image_1.0_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image 1.0 (BF16, 6-bit)",
      "file": "qwen_image_1.0_bf16_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image 1.0 (BF16)",
      "file": "qwen_image_1.0_bf16_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 1.0",
      "file": "qwen_image_edit_1.0_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "kontext",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image Edit](https://huggingface.co/Qwen/Qwen-Image-Edit) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 1.0 (6-bit)",
      "file": "qwen_image_edit_1.0_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "kontext",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image Edit](https://huggingface.co/Qwen/Qwen-Image-Edit) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2509",
      "file": "qwen_image_edit_2509_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEditPlus",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-Edit-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. This is an update in Sep, 2025.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2509 (6-bit)",
      "file": "qwen_image_edit_2509_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEditPlus",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. This is an update in Sep, 2025.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2509 (BF16, 6-bit)",
      "file": "qwen_image_edit_2509_bf16_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEditPlus",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. This is an update in Sep, 2025. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2509 (BF16)",
      "file": "qwen_image_edit_2509_bf16_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEditPlus",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-Edit-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. This is an update in Sep, 2025. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2511",
      "file": "qwen_image_edit_2511_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEdit2511",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image Edit 2511](https://huggingface.co/Qwen/Qwen-Image-Edit-2511) is an enhanced image editing model that significantly improves character consistency, mitigates image drift, and strengthens multi-person fusion capabilities compared to its predecessor (2509). It integrates popular LoRA features natively, enabling advanced lighting control and viewpoint generation without extra tuning, alongside specialized industrial design and geometric reasoning capabilities. It is Apache 2.0-licensed, with 40 inference steps recommended for optimal results.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2511 (6-bit)",
      "file": "qwen_image_edit_2511_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEdit2511",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Qwen Image Edit 2511](https://huggingface.co/Qwen/Qwen-Image-Edit-2511) is an enhanced image editing model that significantly improves character consistency, mitigates image drift, and strengthens multi-person fusion capabilities compared to its predecessor (2509). It integrates popular LoRA features natively, enabling advanced lighting control and viewpoint generation without extra tuning, alongside specialized industrial design and geometric reasoning capabilities. It is Apache 2.0-licensed, with 40 inference steps recommended for optimal results.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2511 (BF16, 6-bit)",
      "file": "qwen_image_edit_2511_bf16_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEdit2511",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image Edit 2511](https://huggingface.co/Qwen/Qwen-Image-Edit-2511) is an enhanced image editing model that significantly improves character consistency, mitigates image drift, and strengthens multi-person fusion capabilities compared to its predecessor (2509). It integrates popular LoRA features natively, enabling advanced lighting control and viewpoint generation without extra tuning, alongside specialized industrial design and geometric reasoning capabilities. It is Apache 2.0-licensed, with 40 inference steps recommended for optimal results. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Edit 2511 (BF16)",
      "file": "qwen_image_edit_2511_bf16_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "modifier": "qwenimageEdit2511",
      "clipEncoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image Edit 2511](https://huggingface.co/Qwen/Qwen-Image-Edit-2511) is an enhanced image editing model that significantly improves character consistency, mitigates image drift, and strengthens multi-person fusion capabilities compared to its predecessor (2509). It integrates popular LoRA features natively, enabling advanced lighting control and viewpoint generation without extra tuning, alongside specialized industrial design and geometric reasoning capabilities. It is Apache 2.0-licensed, with 40 inference steps recommended for optimal results. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Layered 1.0 (BF16, 6-bit)",
      "file": "qwen_image_layered_1.0_bf16_q6p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_layered_vae_f16.ckpt",
      "modifier": "qwenimageLayered",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image Layered](https://huggingface.co/Qwen/Qwen-Image-Layered) is a specialized model capable of decomposing an image into multiple transparent RGBA layers to unlock inherent editability. By physically isolating semantic components, it enables high-fidelity operations such as resizing, repositioning, and recoloring without affecting the rest of the image. It is Apache 2.0-licensed and commercially friendly. The model supports flexible and recursive decomposition, allowing users to define specific layer counts (Batch Size), with a recommended resolution of 640px and 50 inference steps. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Qwen Image Layered 1.0 (BF16)",
      "file": "qwen_image_layered_1.0_bf16_q8p.ckpt",
      "prefix": "",
      "version": "qwen_image",
      "defaultScale": 16,
      "textEncoder": "qwen_2.5_vl_7b_q8p.ckpt",
      "autoencoder": "qwen_image_layered_vae_f16.ckpt",
      "modifier": "qwenimageLayered",
      "hiresFixScale": 24,
      "isBf16": true,
      "note": "[Qwen Image Layered](https://huggingface.co/Qwen/Qwen-Image-Layered) is a specialized model capable of decomposing an image into multiple transparent RGBA layers to unlock inherent editability. By physically isolating semantic components, it enables high-fidelity operations such as resizing, repositioning, and recoloring without affecting the rest of the image. It is Apache 2.0-licensed and commercially friendly. The model supports flexible and recursive decomposition, allowing users to define specific layer counts (Batch Size), with a recommended resolution of 640px and 50 inference steps. The BF16 version is only compatible with macOS 15, iOS 18 and above.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "SDXL Base (v0.9)",
      "file": "sd_xl_base_0.9_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_f16.ckpt",
      "deprecated": true,
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "SDXL Base (v1.0)",
      "file": "sd_xl_base_1.0_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "SDXL Base v1.0 (8-bit)",
      "file": "sd_xl_base_1.0_q6p_q8p.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "SDXL Refiner (v0.9)",
      "file": "sd_xl_refiner_0.9_f16.ckpt",
      "prefix": "",
      "version": "sdxl_refiner_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_f16.ckpt",
      "deprecated": true,
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "SDXL Refiner (v1.0)",
      "file": "sd_xl_refiner_1.0_f16.ckpt",
      "prefix": "",
      "version": "sdxl_refiner_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "SDXL Refiner v1.0 (8-bit)",
      "file": "sd_xl_refiner_1.0_q6p_q8p.ckpt",
      "prefix": "",
      "version": "sdxl_refiner_v0.9",
      "defaultScale": 16,
      "textEncoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clipEncoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Stable Diffusion v1.4",
      "file": "sd_v1.4_f16.ckpt",
      "prefix": "",
      "version": "v1",
      "deprecated": true
    },
    {
      "name": "Stable Diffusion v1.5",
      "file": "sd_v1.5_f16.ckpt",
      "prefix": "",
      "version": "v1"
    },
    {
      "name": "Stable Diffusion v1.5 Inpainting",
      "file": "sd_v1.5_inpainting_f16.ckpt",
      "prefix": "",
      "version": "v1",
      "modifier": "inpainting"
    },
    {
      "name": "Stable Diffusion v2.0",
      "file": "sd_v2.0_f16.ckpt",
      "prefix": "",
      "version": "v2",
      "textEncoder": "open_clip_vit_h14_f16.ckpt",
      "deprecated": true
    },
    {
      "name": "Stable Diffusion v2.0 768-v",
      "file": "sd_v2.0_768_v_f16.ckpt",
      "prefix": "",
      "version": "v2",
      "defaultScale": 12,
      "textEncoder": "open_clip_vit_h14_f16.ckpt",
      "deprecated": true
    },
    {
      "name": "Stable Diffusion v2.0 Depth",
      "file": "sd_v2.0_depth_f16.ckpt",
      "prefix": "",
      "version": "v2",
      "textEncoder": "open_clip_vit_h14_f16.ckpt",
      "modifier": "depth"
    },
    {
      "name": "Stable Diffusion v2.0 Inpainting",
      "file": "sd_v2.0_inpainting_f16.ckpt",
      "prefix": "",
      "version": "v2",
      "textEncoder": "open_clip_vit_h14_f16.ckpt",
      "modifier": "inpainting"
    },
    {
      "name": "Stable Diffusion v2.1",
      "file": "sd_v2.1_f16.ckpt",
      "prefix": "",
      "version": "v2",
      "textEncoder": "open_clip_vit_h14_f16.ckpt"
    },
    {
      "name": "Stable Diffusion v2.1 768-v",
      "file": "sd_v2.1_768_v_f16.ckpt",
      "prefix": "",
      "version": "v2",
      "upcastAttention": true,
      "defaultScale": 12,
      "textEncoder": "open_clip_vit_h14_f16.ckpt"
    },
    {
      "name": "Stable Video Diffusion I2V XT 1.0 (8-bit)",
      "file": "svd_i2v_xt_1.0_q6p_q8p.ckpt",
      "prefix": "",
      "version": "svd_i2v",
      "defaultScale": 8,
      "textEncoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "deprecated": true,
      "clipEncoder": "svd_i2v_xt_1.0_q6p_q8p.ckpt"
    },
    {
      "name": "Stable Video Diffusion I2V XT v1.0",
      "file": "svd_i2v_xt_1.0_f16.ckpt",
      "prefix": "",
      "version": "svd_i2v",
      "defaultScale": 8,
      "textEncoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "deprecated": true,
      "clipEncoder": "svd_i2v_xt_1.0_f16.ckpt"
    },
    {
      "name": "Wan 2.1 I2V 14B 480p",
      "file": "wan_v2.1_14b_i2v_480p_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 8,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "clipEncoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "hiresFixScale": 12,
      "teaCacheCoefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 I2V 14B 480P](https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 832×480. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 I2V 14B 480p (6-bit, SVDQuant)",
      "file": "wan_v2.1_14b_i2v_480p_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 8,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "clipEncoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "hiresFixScale": 12,
      "builtinLora": true,
      "teaCacheCoefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 I2V 14B 480P](https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 832×480. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 I2V 14B 720p",
      "file": "wan_v2.1_14b_i2v_720p_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "clipEncoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "hiresFixScale": 16,
      "teaCacheCoefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 I2V 14B 720P](https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-720P) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 I2V 14B 720p (6-bit, SVDQuant)",
      "file": "wan_v2.1_14b_i2v_720p_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "clipEncoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 I2V 14B 720P](https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-720P) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 T2V 1.3B",
      "file": "wan_v2.1_1.3b_480p_f16.ckpt",
      "prefix": "",
      "version": "wan_v2.1_1.3b",
      "defaultScale": 8,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 12,
      "teaCacheCoefficients": [
        -52186.2437,
        9230.41404,
        -528.275948,
        13.6987616,
        -0.0499875664
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 T2V 1.3B](https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 832×480. The model supports up to 81 frames, with a recommended shift value of 6.0. For best results, set Text Guidance above 5.0. Wan2.1 is trained with a Flow Matching objective, and trailing samplers will produce the best outputs.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 T2V 1.3B (8-bit)",
      "file": "wan_v2.1_1.3b_480p_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_1.3b",
      "defaultScale": 8,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 12,
      "teaCacheCoefficients": [
        -52186.2437,
        9230.41404,
        -528.275948,
        13.6987616,
        -0.0499875664
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 T2V 1.3B](https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 832×480. The model supports up to 81 frames, with a recommended shift value of 6.0. For best results, set Text Guidance above 5.0. Wan2.1 is trained with a Flow Matching objective, and trailing samplers will produce the best outputs.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 T2V 14B",
      "file": "wan_v2.1_14b_720p_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 T2V 14B](https://huggingface.co/Wan-AI/Wan2.1-T2V-14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The recommended resolutions are 832×480. The model supports up to 81 frames, with a recommended shift value of 5.0. For best results, set Text Guidance above 5.0. Wan2.1 is trained with a Flow Matching objective, and trailing samplers will produce the best outputs.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 T2V 14B (5-bit, SVDQuant)",
      "file": "wan_v2.1_14b_720p_q5p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "deprecated": true,
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 T2V 14B](https://huggingface.co/Wan-AI/Wan2.1-T2V-14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.1 T2V 14B (6-bit, SVDQuant)",
      "file": "wan_v2.1_14b_720p_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.1 T2V 14B](https://huggingface.co/Wan-AI/Wan2.1-T2V-14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 High Noise Expert I2V A14B",
      "file": "wan_v2.2_a14b_hne_i2v_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "hiresFixScale": 16,
      "teaCacheCoefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 I2V A14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 High Noise Expert I2V A14B (6-bit, SVDQuant)",
      "file": "wan_v2.2_a14b_hne_i2v_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 I2V A14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 High Noise Expert T2V A14B",
      "file": "wan_v2.2_a14b_hne_t2v_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 T2V A14B](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 High Noise Expert T2V A14B (6-bit, SVDQuant)",
      "file": "wan_v2.2_a14b_hne_t2v_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 T2V A14B](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 Low Noise Expert I2V A14B",
      "file": "wan_v2.2_a14b_lne_i2v_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "hiresFixScale": 16,
      "teaCacheCoefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 I2V A14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 Low Noise Expert I2V A14B (6-bit, SVDQuant)",
      "file": "wan_v2.2_a14b_lne_i2v_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "modifier": "inpainting",
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 I2V A14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) is a state-of-the-art image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length from a given start frame. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 Low Noise Expert T2V A14B",
      "file": "wan_v2.2_a14b_lne_t2v_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 T2V A14B](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 Low Noise Expert T2V A14B (6-bit, SVDQuant)",
      "file": "wan_v2.2_a14b_lne_t2v_q6p_svd.ckpt",
      "prefix": "",
      "version": "wan_v2.1_14b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "builtinLora": true,
      "teaCacheCoefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "framesPerSecond": 16,
      "note": "[Wan2.2 T2V A14B](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B) is a state-of-the-art text-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 81 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 TI2V 5B",
      "file": "wan_v2.2_5b_ti2v_f16.ckpt",
      "prefix": "",
      "version": "wan_v2.2_5b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.2_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "teaCacheCoefficients": null,
      "framesPerSecond": 24,
      "note": "[Wan2.2 TI2V 5B](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B) is a state-of-the-art text-image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 121 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Wan 2.2 TI2V 5B (8-bit)",
      "file": "wan_v2.2_5b_ti2v_q8p.ckpt",
      "prefix": "",
      "version": "wan_v2.2_5b",
      "defaultScale": 12,
      "textEncoder": "umt5_xxl_encoder_q8p.ckpt",
      "autoencoder": "wan_v2.2_video_vae_f16.ckpt",
      "hiresFixScale": 16,
      "teaCacheCoefficients": null,
      "framesPerSecond": 24,
      "note": "[Wan2.2 TI2V 5B](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B) is a state-of-the-art text-image-to-video model developed by Alibaba. It can generate video clips of up to 4 seconds in length. The recommended resolutions are 1280×720. The model supports up to 121 frames, with a recommended shift value of 5.0.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Z Image Turbo 1.0",
      "file": "z_image_turbo_1.0_q8p.ckpt",
      "prefix": "",
      "version": "zImage",
      "defaultScale": 16,
      "textEncoder": "qwen_3_vl_4b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Z Image Turbo](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo) is is a powerful and highly efficient image generation model with 6B parameters. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 8 sampling steps recommended.",
      "copyright": "© 2025 Alibaba"
    },
    {
      "name": "Z Image Turbo 1.0 (6-bit)",
      "file": "z_image_turbo_1.0_q6p.ckpt",
      "prefix": "",
      "version": "zImage",
      "defaultScale": 16,
      "textEncoder": "qwen_3_vl_4b_instruct_q8p.ckpt",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "hiresFixScale": 24,
      "note": "[Z Image Turbo](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo) is is a powerful and highly efficient image generation model with 6B parameters. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 8 sampling steps recommended.",
      "copyright": "© 2025 Alibaba"
    }
  ],
  "officialCnets": [
    {
      "name": "Canny Edge Map (SD v1.x, ControlNet 1.0)",
      "file": "controlnet_canny_1.x_f16.ckpt",
      "modifier": "canny",
      "version": "v1",
      "type": "controlnet",
      "deprecated": true
    },
    {
      "name": "Canny Edge Map (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_canny_1.x_v1.1_f16.ckpt",
      "modifier": "canny",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Canny Edge Map (SD v1.x, T2I Adapter)",
      "file": "t2iadapter_canny_1.x_f16.ckpt",
      "modifier": "canny",
      "version": "v1",
      "type": "t2iadapter"
    },
    {
      "name": "Canny Edge Map (SD v2.x, ControlNet)",
      "file": "controlnet_canny_2.x_f16.ckpt",
      "modifier": "canny",
      "version": "v2",
      "type": "controlnet"
    },
    {
      "name": "Canny Edge Map (SDXL, ControlNet, Diffusers 1.0 Mid)",
      "file": "controlnet_canny_sdxl_v1.0_mid_f16.ckpt",
      "modifier": "canny",
      "version": "sdxl_base_v0.9",
      "type": "controlnet",
      "transformerBlocks": [
        0,
        0,
        1,
        1
      ]
    },
    {
      "name": "Color Palette (SD v1.x, T2I Adapter)",
      "file": "t2iadapter_color_1.x_f16.ckpt",
      "modifier": "color",
      "version": "v1",
      "type": "t2iadapter"
    },
    {
      "name": "Depth Map (SD v1.x, ControlNet 1.0)",
      "file": "controlnet_depth_1.x_f16.ckpt",
      "modifier": "depth",
      "version": "v1",
      "type": "controlnet",
      "deprecated": true
    },
    {
      "name": "Depth Map (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_depth_1.x_v1.1_f16.ckpt",
      "modifier": "depth",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Depth Map (SD v1.x, T2I Adapter)",
      "file": "t2iadapter_depth_1.x_f16.ckpt",
      "modifier": "depth",
      "version": "v1",
      "type": "t2iadapter"
    },
    {
      "name": "Depth Map (SD v2.x, ControlNet)",
      "file": "controlnet_depth_2.x_f16.ckpt",
      "modifier": "depth",
      "version": "v2",
      "type": "controlnet"
    },
    {
      "name": "Depth Map (SDXL, ControlNet, Diffusers 1.0 Mid)",
      "file": "controlnet_depth_sdxl_v1.0_mid_f16.ckpt",
      "modifier": "depth",
      "version": "sdxl_base_v0.9",
      "type": "controlnet",
      "transformerBlocks": [
        0,
        0,
        1,
        1
      ]
    },
    {
      "name": "Inpainting (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_inpaint_1.x_v1.1_f16.ckpt",
      "modifier": "inpaint",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Instruct Pix2Pix (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_ip2p_1.x_v1.1_f16.ckpt",
      "modifier": "ip2p",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "IP Adapter Full Face (SD v1.x)",
      "file": "ip_adapter_full_face_sd_v1.x_open_clip_h14_f16.ckpt",
      "modifier": "shuffle",
      "version": "v1",
      "type": "ipadapterfull",
      "imageEncoder": "open_clip_vit_h14_vision_model_f16.ckpt"
    },
    {
      "name": "IP Adapter Plus (SD v1.x)",
      "file": "ip_adapter_plus_sd_v1.x_open_clip_h14_f16.ckpt",
      "modifier": "shuffle",
      "version": "v1",
      "type": "ipadapterplus",
      "imageEncoder": "open_clip_vit_h14_vision_model_f16.ckpt"
    },
    {
      "name": "IP Adapter Plus (SDXL Base)",
      "file": "ip_adapter_plus_xl_base_open_clip_h14_f16.ckpt",
      "modifier": "shuffle",
      "version": "sdxl_base_v0.9",
      "type": "ipadapterplus",
      "imageEncoder": "open_clip_vit_h14_vision_model_f16.ckpt"
    },
    {
      "name": "IP Adapter Plus Face (SD v1.x)",
      "file": "ip_adapter_plus_face_sd_v1.x_open_clip_h14_f16.ckpt",
      "modifier": "shuffle",
      "version": "v1",
      "type": "ipadapterplus",
      "imageEncoder": "open_clip_vit_h14_vision_model_f16.ckpt"
    },
    {
      "name": "IP Adapter Plus Face (SDXL Base)",
      "file": "ip_adapter_plus_face_xl_base_open_clip_h14_f16.ckpt",
      "modifier": "shuffle",
      "version": "sdxl_base_v0.9",
      "type": "ipadapterplus",
      "imageEncoder": "open_clip_vit_h14_vision_model_f16.ckpt"
    },
    {
      "name": "LineArt (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_lineart_1.x_v1.1_f16.ckpt",
      "modifier": "lineart",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "LineArt Anime (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_lineart_anime_1.x_v1.1_f16.ckpt",
      "modifier": "lineart",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "MLSD Hough Map (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_mlsd_1.x_v1.1_f16.ckpt",
      "modifier": "mlsd",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Normal Map (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_normalbae_1.x_v1.1_f16.ckpt",
      "modifier": "normalbae",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Pose (SD v1.x, ControlNet 1.0)",
      "file": "controlnet_openpose_1.x_f16.ckpt",
      "modifier": "pose",
      "version": "v1",
      "type": "controlnet",
      "deprecated": true
    },
    {
      "name": "Pose (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_openpose_1.x_v1.1_f16.ckpt",
      "modifier": "pose",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Pose (SD v1.x, T2I Adapter)",
      "file": "t2iadapter_openpose_1.x_f16.ckpt",
      "modifier": "pose",
      "version": "v1",
      "type": "t2iadapter"
    },
    {
      "name": "Pose (SD v2.x, ControlNet)",
      "file": "controlnet_openpose_2.x_f16.ckpt",
      "modifier": "pose",
      "version": "v2",
      "type": "controlnet"
    },
    {
      "name": "QR Code (SD v1.x, ControlNet Monster 2.0)",
      "file": "controlnet_qr_code_monster_1.x_v2.0_f16.ckpt",
      "modifier": "scribble",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Scribble (SD v1.x, ControlNet 1.0)",
      "file": "controlnet_scribble_1.x_f16.ckpt",
      "modifier": "scribble",
      "version": "v1",
      "type": "controlnet",
      "preprocessor": "hed_f16.ckpt",
      "deprecated": true
    },
    {
      "name": "Scribble (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_scribble_1.x_v1.1_f16.ckpt",
      "modifier": "scribble",
      "version": "v1",
      "type": "controlnet",
      "preprocessor": "hed_f16.ckpt"
    },
    {
      "name": "Scribble (SD v1.x, T2I Adapter)",
      "file": "t2iadapter_sketch_1.x_f16.ckpt",
      "modifier": "scribble",
      "version": "v1",
      "type": "t2iadapter"
    },
    {
      "name": "Scribble (SD v2.x, ControlNet)",
      "file": "controlnet_scribble_2.x_f16.ckpt",
      "modifier": "scribble",
      "version": "v2",
      "type": "controlnet",
      "preprocessor": "hed_f16.ckpt"
    },
    {
      "name": "Segmentation (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_seg_1.x_v1.1_f16.ckpt",
      "modifier": "seg",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "Shuffle (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_shuffle_1.x_v1.1_f16.ckpt",
      "modifier": "shuffle",
      "version": "v1",
      "type": "controlnet",
      "globalAveragePooling": true
    },
    {
      "name": "Soft Edge (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_softedge_1.x_v1.1_f16.ckpt",
      "modifier": "softedge",
      "version": "v1",
      "type": "controlnet",
      "preprocessor": "hed_f16.ckpt"
    },
    {
      "name": "Tile (SD v1.x, ControlNet 1.1)",
      "file": "controlnet_tile_1.x_v1.1_f16.ckpt",
      "modifier": "tile",
      "version": "v1",
      "type": "controlnet"
    },
    {
      "name": "VACE (Wan 2.1, 1.3B)",
      "file": "wan_v2.1_1.3b_vace_480p_f16.ckpt",
      "modifier": "shuffle",
      "version": "wan_v2.1_1.3b",
      "type": "controlnet"
    },
    {
      "name": "VACE (Wan 2.1, 1.3B) (8-bit)",
      "file": "wan_v2.1_1.3b_vace_480p_q8p.ckpt",
      "modifier": "shuffle",
      "version": "wan_v2.1_1.3b",
      "type": "controlnet"
    },
    {
      "name": "VACE (Wan 2.1, 14B)",
      "file": "wan_v2.1_14b_vace_720p_f16.ckpt",
      "modifier": "shuffle",
      "version": "wan_v2.1_14b",
      "type": "controlnet"
    },
    {
      "name": "VACE (Wan 2.1, 14B) (8-bit)",
      "file": "wan_v2.1_14b_vace_720p_q8p.ckpt",
      "modifier": "shuffle",
      "version": "wan_v2.1_14b",
      "type": "controlnet"
    }
  ],
  "officialLoras": [
    {
      "name": "Fooocus Inpaint v2.6",
      "file": "fooocus_inpaint_v2.6_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "modifier": "inpainting"
    },
    {
      "name": "Fooocus Inpaint v2.6 (8-bit)",
      "file": "fooocus_inpaint_v2.6_lora_q8p.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "modifier": "inpainting"
    },
    {
      "name": "Foreground to Blending",
      "file": "layer_xl_fg2ble_v1.0_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "modifier": "inpainting"
    },
    {
      "name": "LCM SDXL Base (1.0)",
      "file": "lcm_sd_xl_base_1.0_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "isConsistencyModel": true
    },
    {
      "name": "LCM SDXL Refiner (1.0)",
      "file": "lcm_sd_xl_refiner_1.0_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_refiner_v0.9",
      "isConsistencyModel": true
    },
    {
      "name": "LCM Stable Diffusion v1.5",
      "file": "lcm_sd_v1.5_lora_f16.ckpt",
      "prefix": "",
      "version": "v1",
      "isConsistencyModel": true
    },
    {
      "name": "SDXL Offset (1.0)",
      "file": "sdxl_offset_v1.0_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "TCD SDXL Base (1.0)",
      "file": "tcd_sd_xl_base_1.0_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "isConsistencyModel": true
    },
    {
      "name": "TCD Stable Diffusion v1.5",
      "file": "tcd_sd_v1.5_lora_f16.ckpt",
      "prefix": "",
      "version": "v1",
      "isConsistencyModel": true
    },
    {
      "name": "Transparent Image",
      "file": "layer_flux_1_transparent_lora_f16.ckpt",
      "prefix": "",
      "version": "flux1",
      "alternativeDecoder": "flux_1_transparent_vae_decoder_f16.ckpt",
      "alternativeDecoderVersion": "transparent"
    },
    {
      "name": "Transparent Image (Attention Injection)",
      "file": "layer_xl_transparent_attn_v1.0_lora_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "alternativeDecoder": "transparent_vae_decoder_v1.0_f16.ckpt",
      "alternativeDecoderVersion": "transparent"
    }
  ],
  "communityModels": [
    {
      "version": "v1",
      "prefix": "redshift style ",
      "upcast_attention": false,
      "default_scale": 8,
      "file": "redshift_v1_f16.ckpt",
      "text_encoder": "redshift_v1_clip_vit_l14_f16.ckpt",
      "name": "3D Model (Redshift v1)"
    },
    {
      "name": "3D Model 768 (Redshift 768)",
      "objective": {
        "v": {}
      },
      "file": "redshift_768_v_f16.ckpt",
      "version": "v2",
      "upcast_attention": false,
      "prefix": "redshift style ",
      "text_encoder": "redshift_768_v_open_clip_vit_h14_f16.ckpt",
      "default_scale": 12
    },
    {
      "upcast_attention": false,
      "version": "v1",
      "name": "AloeVera's SimpMaker 3K1",
      "file": "aloeveras_simpmaker_3k1_f16.ckpt",
      "prefix": "",
      "default_scale": 8
    },
    {
      "name": "Analog (v1)",
      "prefix": "analog style ",
      "default_scale": 8,
      "version": "v1",
      "upcast_attention": false,
      "file": "analog_v1_f16.ckpt",
      "text_encoder": "analog_v1_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Animagine XL v3.1",
      "modifier": "none",
      "text_encoder": "animagine_xl_v3.1_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "animagine_xl_v3.1_clip_vit_l14_f16.ckpt",
      "file": "animagine_xl_v3.1_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Animagine XL v3.1 (8-bit)",
      "modifier": "none",
      "text_encoder": "animagine_xl_v3.1_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "animagine_xl_v3.1_clip_vit_l14_f16.ckpt",
      "file": "animagine_xl_v3.1_q6p_q8p.ckpt"
    },
    {
      "prefix": "",
      "upcast_attention": false,
      "clip_encoder": "open_clip_vit_h14_visual_proj_f16.ckpt",
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "conditioning": "noise",
      "version": "svd_i2v",
      "default_scale": 8,
      "name": "AnimateLCM SVD XT v1.1",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_max": 700,
            "sigma_data": 0.5,
            "sigma_min": 0.002
          }
        }
      },
      "modifier": "none",
      "objective": {
        "v": {}
      },
      "file": "animatelcm_svd_xt_v1.1_f16.ckpt"
    },
    {
      "prefix": "",
      "upcast_attention": false,
      "clip_encoder": "open_clip_vit_h14_visual_proj_f16.ckpt",
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "conditioning": "noise",
      "version": "svd_i2v",
      "default_scale": 8,
      "name": "AnimateLCM SVD XT v1.1 (8-bit)",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_max": 700,
            "sigma_data": 0.5,
            "sigma_min": 0.002
          }
        }
      },
      "modifier": "none",
      "objective": {
        "v": {}
      },
      "file": "animatelcm_svd_xt_v1.1_q6p_q8p.ckpt"
    },
    {
      "text_encoder": "anything_v3_clip_vit_l14_f16.ckpt",
      "default_scale": 8,
      "version": "v1",
      "file": "anything_v3_f16.ckpt",
      "prefix": "",
      "autoencoder": "anything_v3_vae_f16.ckpt",
      "name": "Anime (Anything v3)",
      "upcast_attention": false
    },
    {
      "upcast_attention": false,
      "version": "v1",
      "file": "wd_v1.3_f16.ckpt",
      "prefix": "",
      "name": "Anime (Waifu Diffusion v1.3)",
      "default_scale": 8
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B High Noise Expert",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_hne_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation."
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B High Noise Expert (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_hne_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "builtin_lora": true
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B Low Noise Expert",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_lne_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation."
    },
    {
      "name": "AniSora v3.2 I2V Wan 2.2 A14B Low Noise Expert (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v3.2_i2v_wan_2.2_a14b_lne_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[AniSora v3.2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "builtin_lora": true
    },
    {
      "file": "arcane_v3_f16.ckpt",
      "text_encoder": "arcane_v3_clip_vit_l14_f16.ckpt",
      "name": "Arcane (v3)",
      "default_scale": 8,
      "prefix": "arcane style ",
      "upcast_attention": false,
      "version": "v1"
    },
    {
      "name": "Artsy Vibe v1",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "artsy_vibe_v1_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "Artsy Vibe v1 (5-bit, SVDQuant)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "artsy_vibe_v1_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "builtin_lora": true
    },
    {
      "name": "Balloon Art (v1)",
      "upcast_attention": false,
      "version": "v1",
      "file": "balloonart_v1_f16.ckpt",
      "prefix": "balloonart ",
      "default_scale": 8,
      "text_encoder": "balloonart_v1_clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Chroma v47 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v47_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v47 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v47_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v48 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v48_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v48 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v48_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma1 HD",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_1_hd_r0.1_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma1 HD](https://huggingface.co/lodestones/Chroma1-HD)."
    },
    {
      "name": "Chroma1 HD (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_1_hd_r0.1_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma1 HD](https://huggingface.co/lodestones/Chroma1-HD)."
    },
    {
      "name": "ChronoEdit 14B",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 15,
      "hires_fix_scale": 16,
      "file": "chronoedit_14b_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[ChronoEdit 14B](https://research.nvidia.com/labs/toronto-ai/chronoedit/) is a image edit model fine-tuned from Wan 2.1 14B video model, that prefers 29-frame or 5-frame generation."
    },
    {
      "name": "ChronoEdit 14B (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 15,
      "hires_fix_scale": 16,
      "file": "chronoedit_14b_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[ChronoEdit 14B](https://research.nvidia.com/labs/toronto-ai/chronoedit/) is a image edit model fine-tuned from Wan 2.1 14B video model, that prefers 29-frame or 5-frame generation.",
      "builtin_lora": true
    },
    {
      "text_encoder": "classicanim_v1_clip_vit_l14_f16.ckpt",
      "default_scale": 8,
      "version": "v1",
      "file": "classicanim_v1_f16.ckpt",
      "prefix": "classic disney style ",
      "name": "Classic Animation (v1)",
      "upcast_attention": false
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "ColorfulXL v6.0",
      "modifier": "none",
      "clip_encoder": "colorfulxl_v6.0_clip_vit_l14_f16.ckpt",
      "file": "colorfulxl_v6.0_f16.ckpt",
      "text_encoder": "colorfulxl_v6.0_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "ColorfulXL v6.0 (8-bit)",
      "modifier": "none",
      "clip_encoder": "colorfulxl_v6.0_clip_vit_l14_f16.ckpt",
      "file": "colorfulxl_v6.0_q6p_q8p.ckpt",
      "text_encoder": "colorfulxl_v6.0_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "version": "v1",
      "default_scale": 8,
      "prefix": "",
      "name": "Counterfeit v3.0",
      "upcast_attention": false,
      "modifier": "none",
      "file": "counterfeit_v3.0_f16.ckpt",
      "text_encoder": "counterfeit_v3.0_clip_vit_l14_f16.ckpt"
    },
    {
      "version": "v1",
      "default_scale": 8,
      "prefix": "",
      "name": "Counterfeit v3.0 (8-bit)",
      "upcast_attention": false,
      "modifier": "none",
      "file": "counterfeit_v3.0_q6p_q8p.ckpt",
      "text_encoder": "counterfeit_v3.0_clip_vit_l14_f16.ckpt"
    },
    {
      "prefix": "dgs illustration style ",
      "file": "cyberpunk_anime_f16.ckpt",
      "default_scale": 8,
      "upcast_attention": false,
      "version": "v1",
      "name": "Cyberpunk Anime",
      "text_encoder": "cyberpunk_anime_clip_vit_l14_f16.ckpt"
    },
    {
      "version": "v1",
      "name": "Deliberate v2.0 (8-bit)",
      "file": "deliberate_v2_q6p_q8p.ckpt",
      "prefix": "",
      "text_encoder": "deliberate_v2_clip_vit_l14_f16.ckpt",
      "default_scale": 8,
      "upcast_attention": false
    },
    {
      "name": "devMODE v0.3 Turbo",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "devmode_v0.3_turbo_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "devMODE v0.3 Turbo (5-bit, SVDQuant)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "devmode_v0.3_turbo_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "builtin_lora": true
    },
    {
      "default_scale": 8,
      "text_encoder": "disney_pixar_cartoon_type_b_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "prefix": "",
      "file": "disney_pixar_cartoon_type_b_q6p_q8p.ckpt",
      "name": "Disney Pixar Cartoon Type B (8-bit)",
      "version": "v1"
    },
    {
      "file": "dnd_classes_and_species_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "default_scale": 8,
      "version": "v1",
      "text_encoder": "dnd_classes_and_species_clip_vit_l14_f16.ckpt",
      "name": "DnD Classes and Species"
    },
    {
      "version": "v1",
      "default_scale": 12,
      "prefix": "",
      "name": "DreamShaper v8",
      "upcast_attention": false,
      "file": "dreamshaper_v8_f16.ckpt",
      "text_encoder": "dreamshaper_v8_clip_vit_l14_f16.ckpt",
      "modifier": "none"
    },
    {
      "version": "v1",
      "default_scale": 12,
      "prefix": "",
      "name": "DreamShaper v8 (8-bit)",
      "upcast_attention": false,
      "file": "dreamshaper_v8_q6p_q8p.ckpt",
      "text_encoder": "dreamshaper_v8_clip_vit_l14_f16.ckpt",
      "modifier": "none"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "DreamShaper XL v2.1 Turbo",
      "modifier": "none",
      "clip_encoder": "dreamshaper_xl_v2.1_turbo_clip_vit_l14_f16.ckpt",
      "file": "dreamshaper_xl_v2.1_turbo_f16.ckpt",
      "text_encoder": "dreamshaper_xl_v2.1_turbo_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "DreamShaper XL v2.1 Turbo (8-bit)",
      "modifier": "none",
      "clip_encoder": "dreamshaper_xl_v2.1_turbo_clip_vit_l14_f16.ckpt",
      "file": "dreamshaper_xl_v2.1_turbo_q6p_q8p.ckpt",
      "text_encoder": "dreamshaper_xl_v2.1_turbo_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "version": "v1",
      "file": "dnd_30000_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "upcast_attention": false,
      "name": "Dungeons and Diffusion (30000)",
      "text_encoder": "dnd_30000_clip_vit_l14_f16.ckpt"
    },
    {
      "prefix": "elden ring style ",
      "upcast_attention": false,
      "name": "Elden Ring (v3)",
      "file": "eldenring_v3_f16.ckpt",
      "default_scale": 8,
      "text_encoder": "eldenring_v3_clip_vit_l14_f16.ckpt",
      "version": "v1"
    },
    {
      "upcast_attention": false,
      "version": "v1",
      "name": "F222",
      "file": "f222_f16.ckpt",
      "prefix": "",
      "default_scale": 8
    },
    {
      "name": "FLUX.1 [dev]",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 [dev] (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_dev_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 [dev] (Exact)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_dev_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 [dev] De-distill",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_dev_de_distill_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 [dev] De-distill (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_dev_de_distill_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 Canny [dev]",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "canny",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_canny_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "FLUX.1 Canny [dev] (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "canny",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_canny_dev_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "FLUX.1 Depth [dev]",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "depth",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_depth_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "FLUX.1 Depth [dev] (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "depth",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_depth_dev_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "FLUX.1 Fill [dev]",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "inpainting",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_fill_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 128,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "FLUX.1 Fill [dev] (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "inpainting",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_fill_dev_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 128,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "FLUX.1 Kontext [dev]",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "kontext",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_kontext_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 Kontext [dev] (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "kontext",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_kontext_dev_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 Kontext [dev] (Exact)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "modifier": "kontext",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_kontext_dev_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 Krea [dev]",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_krea_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.1 Krea [dev] (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "flux_1_krea_dev_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "FLUX.2 [dev]",
      "version": "flux2",
      "autoencoder": "flux_2_vae_f16.ckpt",
      "prefix": "",
      "modifier": "kontext",
      "default_scale": 16,
      "hires_fix_scale": 32,
      "file": "flux_2_dev_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "mistral_small_3.2_24b_instruct_2506_q8p.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[FLUX.2 [dev]](https://huggingface.co/black-forest-labs/FLUX.2-dev) is a 32 billion parameter rectified flow transformer capable of generating, editing and combining images based on text instructions.",
      "copyright": "© 2025 Black Forest Labs"
    },
    {
      "name": "FLUX.2 [dev] (6-bit)",
      "version": "flux2",
      "autoencoder": "flux_2_vae_f16.ckpt",
      "prefix": "",
      "modifier": "kontext",
      "default_scale": 16,
      "hires_fix_scale": 32,
      "file": "flux_2_dev_q6p.ckpt",
      "upcast_attention": false,
      "text_encoder": "mistral_small_3.2_24b_instruct_2506_q8p.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[FLUX.2 [dev]](https://huggingface.co/black-forest-labs/FLUX.2-dev) is a 32 billion parameter rectified flow transformer capable of generating, editing and combining images based on text instructions.",
      "copyright": "© 2025 Black Forest Labs"
    },
    {
      "name": "FLUX.2 [dev] (Exact)",
      "version": "flux2",
      "autoencoder": "flux_2_vae_f16.ckpt",
      "prefix": "",
      "modifier": "kontext",
      "default_scale": 16,
      "hires_fix_scale": 32,
      "file": "flux_2_dev_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "mistral_small_3.2_24b_instruct_2506_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[FLUX.2 [dev]](https://huggingface.co/black-forest-labs/FLUX.2-dev) is a 32 billion parameter rectified flow transformer capable of generating, editing and combining images based on text instructions.",
      "copyright": "© 2025 Black Forest Labs"
    },
    {
      "upcast_attention": false,
      "prefix": "ghibli style ",
      "text_encoder": "ghibli_v1_clip_vit_l14_f16.ckpt",
      "default_scale": 8,
      "file": "ghibli_v1_f16.ckpt",
      "name": "Ghibli (v1)",
      "version": "v1"
    },
    {
      "file": "hna_3dkx_1.1_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "hna_3dkx_1.1_clip_vit_l14_f16.ckpt",
      "default_scale": 8,
      "version": "v1",
      "name": "H&A's 3DKX 1.1",
      "prefix": "a 3d render / cartoon of "
    },
    {
      "version": "v1",
      "file": "hassanblend_v1.5.1.2_f16.ckpt",
      "prefix": "",
      "text_encoder": "hassanblend_v1.5.1.2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 8,
      "name": "Hassanblend (v1.5.1.2)"
    },
    {
      "name": "HiDream E1-1 (Exact)",
      "version": "hidream_i1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "modifier": "editing",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "hidream_e1_1_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "additional_clip_encoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 128,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[HiDream-E1-1](https://huggingface.co/HiDream-ai/HiDream-E1-1) is an image editing model built on HiDream-I1. It is MIT-licensed and commercially friendly. Trained at dynamic resolutions (around 1MP) using a Flow Matching objective, the model performs best with trailing samplers and 30–50 sampling steps."
    },
    {
      "name": "HiDream I1 [dev] (Exact)",
      "version": "hidream_i1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "hidream_i1_dev_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "additional_clip_encoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 128,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[HiDream-I1 [dev]](https://huggingface.co/HiDream-ai/HiDream-I1-Dev) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 20–30 sampling steps recommended. Text guidance is not effective for this model."
    },
    {
      "name": "HiDream I1 [fast] (Exact)",
      "version": "hidream_i1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "hidream_i1_fast_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "additional_clip_encoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 128,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[HiDream-I1 [fast]](https://huggingface.co/HiDream-ai/HiDream-I1-Fast) is a state-of-the-art open-source image generation model known for its strong prompt adherence across diverse styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 10–20 sampling steps recommended. Text guidance is not effective for this model."
    },
    {
      "name": "HiDream I1 [full] (Exact)",
      "version": "hidream_i1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "hidream_i1_full_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "llama_3.1_8b_instruct_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_f16.ckpt",
      "clip_encoder": "long_clip_vit_l14_f16.ckpt",
      "additional_clip_encoders": [
        "long_open_clip_vit_bigg14_f16.ckpt"
      ],
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 128,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[HiDream-I1 [full]](https://huggingface.co/HiDream-ai/HiDream-I1-Full) is a state-of-the-art open-source image generation model known for its exceptional prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is MIT-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended."
    },
    {
      "name": "Hunyuan Video T2V 720p",
      "version": "hunyuan_video",
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 24,
      "file": "hunyuan_video_t2v_720p_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": false,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 30,
      "tea_cache_coefficients": [
        733.226126,
        -401.131952,
        67.5869174,
        -3.149878,
        0.0961237896
      ],
      "note": "[Hunyuan Video](https://huggingface.co/tencent/HunyuanVideo) is a state-of-the-art text-to-video model developed by Tencent. It can generate video clips of up to 5 seconds in length. The recommended resolutions are 960×544 or 1280×720. The model supports up to 129 frames, with a recommended shift value of 7.0."
    },
    {
      "name": "Hunyuan Video T2V 720p (5-bit, SVDQuant)",
      "version": "hunyuan_video",
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 24,
      "file": "hunyuan_video_t2v_720p_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": false,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 30,
      "tea_cache_coefficients": [
        733.226126,
        -401.131952,
        67.5869174,
        -3.149878,
        0.0961237896
      ],
      "note": "[Hunyuan Video](https://huggingface.co/tencent/HunyuanVideo) is a state-of-the-art text-to-video model developed by Tencent. It can generate video clips of up to 5 seconds in length. The recommended resolutions are 960×544 or 1280×720. The model supports up to 129 frames, with a recommended shift value of 7.0.",
      "builtin_lora": true
    },
    {
      "name": "iCatcher Cartoon",
      "file": "icatcher_cartoon_f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "icatcher_cartoon_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "text_encoder": "icatcher_cartoon_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "name": "iCatcher Cartoon (8-bit)",
      "file": "icatcher_cartoon_q6p_q8p.ckpt",
      "prefix": "",
      "modifier": "none",
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "icatcher_cartoon_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "text_encoder": "icatcher_cartoon_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "name": "iCatcher Realistic",
      "file": "icatcher_realistic_f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "icatcher_realistic_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "icatcher_realistic_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "iCatcher Realistic (8-bit)",
      "file": "icatcher_realistic_q6p_q8p.ckpt",
      "prefix": "",
      "modifier": "none",
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "icatcher_realistic_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "icatcher_realistic_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "version": "v1",
      "file": "inkpunk_v2_f16.ckpt",
      "name": "Inkpunk (v2)",
      "upcast_attention": false,
      "prefix": "nvinkpunk ",
      "default_scale": 8,
      "text_encoder": "inkpunk_v2_clip_vit_l14_f16.ckpt"
    },
    {
      "version": "v1",
      "default_scale": 12,
      "prefix": "",
      "name": "Juggernaut Reborn",
      "upcast_attention": false,
      "file": "juggernaut_reborn_f16.ckpt",
      "text_encoder": "juggernaut_reborn_clip_vit_l14_f16.ckpt",
      "modifier": "none"
    },
    {
      "version": "v1",
      "default_scale": 12,
      "prefix": "",
      "name": "Juggernaut Reborn (8-bit)",
      "upcast_attention": false,
      "file": "juggernaut_reborn_q6p_q8p.ckpt",
      "text_encoder": "juggernaut_reborn_clip_vit_l14_f16.ckpt",
      "modifier": "none"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL Ragnarok",
      "modifier": "none",
      "text_encoder": "juggernaut_xl_ragnarok_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_ragnarok_clip_vit_l14_f16.ckpt",
      "file": "juggernaut_xl_ragnarok_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL Ragnarok (8-bit)",
      "modifier": "none",
      "text_encoder": "juggernaut_xl_ragnarok_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_ragnarok_clip_vit_l14_f16.ckpt",
      "file": "juggernaut_xl_ragnarok_q6p_q8p.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL v9",
      "modifier": "none",
      "text_encoder": "juggernaut_xl_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_clip_vit_l14_f16.ckpt",
      "file": "juggernaut_xl_v9_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL v9 (8-bit)",
      "modifier": "none",
      "text_encoder": "juggernaut_xl_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_clip_vit_l14_f16.ckpt",
      "file": "juggernaut_xl_v9_q6p_q8p.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL v9 Lightning",
      "modifier": "none",
      "file": "juggernaut_xl_v9_lightning_f16.ckpt",
      "text_encoder": "juggernaut_xl_v9_lightning_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_lightning_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL v9 Lightning (8-bit)",
      "modifier": "none",
      "file": "juggernaut_xl_v9_lightning_q6p_q8p.ckpt",
      "text_encoder": "juggernaut_xl_v9_lightning_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "juggernaut_xl_v9_lightning_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL X",
      "modifier": "none",
      "text_encoder": "juggernaut_xl_x_open_clip_vit_bigg14_f16.ckpt",
      "file": "juggernaut_xl_x_f16.ckpt",
      "clip_encoder": "juggernaut_xl_x_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Juggernaut XL X (8-bit)",
      "modifier": "none",
      "text_encoder": "juggernaut_xl_x_open_clip_vit_bigg14_f16.ckpt",
      "file": "juggernaut_xl_x_q6p_q8p.ckpt",
      "clip_encoder": "juggernaut_xl_x_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Kwai Kolors 1.0",
      "modifier": "none",
      "file": "kwai_kolors_1.0_f16.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "text_encoder_version": "chatglm3_6b"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Kwai Kolors 1.0 (8-bit)",
      "modifier": "none",
      "file": "kwai_kolors_1.0_q6p_q8p.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "text_encoder_version": "chatglm3_6b"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": true,
      "name": "Kwai Kolors Inpainting 1.0",
      "modifier": "inpainting",
      "file": "kwai_kolors_inpainting_1.0_f16.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "text_encoder_version": "chatglm3_6b"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": true,
      "name": "Kwai Kolors Inpainting 1.0 (8-bit)",
      "modifier": "inpainting",
      "file": "kwai_kolors_inpainting_1.0_q6p_q8p.ckpt",
      "text_encoder": "chatglm3_6b_q6p_q8p.ckpt",
      "text_encoder_version": "chatglm3_6b"
    },
    {
      "version": "v1",
      "default_scale": 8,
      "prefix": "",
      "name": "MajicMIX Realistic v7",
      "upcast_attention": false,
      "file": "majicmix_realistic_v7_f16.ckpt",
      "text_encoder": "majicmix_realistic_v7_clip_vit_l14_f16.ckpt",
      "modifier": "none"
    },
    {
      "version": "v1",
      "default_scale": 8,
      "prefix": "",
      "name": "MajicMIX Realistic v7 (8-bit)",
      "upcast_attention": false,
      "file": "majicmix_realistic_v7_q6p_q8p.ckpt",
      "text_encoder": "majicmix_realistic_v7_clip_vit_l14_f16.ckpt",
      "modifier": "none"
    },
    {
      "prefix": "modern disney style ",
      "upcast_attention": false,
      "version": "v1",
      "file": "modi_v1_f16.ckpt",
      "name": "Modern Disney (v1)",
      "text_encoder": "modi_v1_clip_vit_l14_f16.ckpt",
      "default_scale": 8
    },
    {
      "file": "nitro_v1_f16.ckpt",
      "default_scale": 8,
      "version": "v1",
      "prefix": "",
      "name": "Multi-Style (Nitro Diffusion v1)",
      "upcast_attention": false,
      "text_encoder": "nitro_v1_clip_vit_l14_f16.ckpt"
    },
    {
      "text_encoder": "mdjrny_v4_clip_vit_l14_f16.ckpt",
      "version": "v1",
      "prefix": "mdjrny-v4 style ",
      "upcast_attention": false,
      "file": "mdjrny_v4_f16.ckpt",
      "name": "Openjourney",
      "default_scale": 8
    },
    {
      "autoencoder": "vae_ft_mse_840000_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "v1",
      "upcast_attention": false,
      "name": "Outfitting Fusion Virtual Try-on (Full-Body)",
      "modifier": "double",
      "file": "ootd_vton_full_body_1.0_f16.ckpt",
      "text_encoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "vae_ft_mse_840000_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "v1",
      "upcast_attention": false,
      "name": "Outfitting Fusion Virtual Try-on (Upper-Body)",
      "modifier": "double",
      "file": "ootd_vton_upper_body_1.0_f16.ckpt",
      "text_encoder": "clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Paper Cut (v1)",
      "upcast_attention": false,
      "version": "v1",
      "file": "papercut_v1_f16.ckpt",
      "prefix": "papercut ",
      "default_scale": 8,
      "text_encoder": "papercut_v1_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "PixelWave 10",
      "modifier": "none",
      "file": "pixelwave_10_f16.ckpt",
      "clip_encoder": "pixelwave_10_clip_vit_l14_f16.ckpt",
      "text_encoder": "pixelwave_10_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "PixelWave 10 (8-bit)",
      "modifier": "none",
      "file": "pixelwave_10_q6p_q8p.ckpt",
      "clip_encoder": "pixelwave_10_clip_vit_l14_f16.ckpt",
      "text_encoder": "pixelwave_10_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "name": "PixelWave FLUX.1 Schnell 04",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "pixelwave_flux_1_schnell_04_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "PixelWave FLUX.1 Schnell 04 (5-bit, SVDQuant)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "pixelwave_flux_1_schnell_04_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "builtin_lora": true
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "PixelWave v9",
      "modifier": "none",
      "text_encoder": "pixelwave_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "pixelwave_v9_clip_vit_l14_f16.ckpt",
      "file": "pixelwave_v9_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "PixelWave v9 (8-bit)",
      "modifier": "none",
      "text_encoder": "pixelwave_v9_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "pixelwave_v9_clip_vit_l14_f16.ckpt",
      "file": "pixelwave_v9_q6p_q8p.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Playground v2",
      "file": "playground_v2_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Playground v2 (8-bit)",
      "file": "playground_v2_q6p_q8p.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none"
    },
    {
      "conditioning": "noise",
      "latents_std": [
        8.4927,
        5.9022,
        6.5498,
        5.2299
      ],
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "objective": {
        "edm": {
          "sigma_data": 0.5
        }
      },
      "prefix": "",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Playground v2.5",
      "file": "playground_v2.5_f16.ckpt",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_min": 0.002,
            "sigma_data": 0.5,
            "sigma_max": 80
          }
        }
      },
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "latents_mean": [
        -1.6574,
        1.886,
        -1.383,
        2.5155
      ],
      "latents_scaling_factor": 0.5
    },
    {
      "conditioning": "noise",
      "latents_std": [
        8.4927,
        5.9022,
        6.5498,
        5.2299
      ],
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "objective": {
        "edm": {
          "sigma_data": 0.5
        }
      },
      "prefix": "",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Playground v2.5 (8-bit)",
      "file": "playground_v2.5_q6p_q8p.ckpt",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_min": 0.002,
            "sigma_data": 0.5,
            "sigma_max": 80
          }
        }
      },
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "latents_mean": [
        -1.6574,
        1.886,
        -1.383,
        2.5155
      ],
      "latents_scaling_factor": 0.5
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Proteus v0.3",
      "modifier": "none",
      "clip_encoder": "proteus_v0.3_clip_vit_l14_f16.ckpt",
      "file": "proteus_v0.3_f16.ckpt",
      "text_encoder": "proteus_v0.3_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Proteus v0.3 (8-bit)",
      "modifier": "none",
      "clip_encoder": "proteus_v0.3_clip_vit_l14_f16.ckpt",
      "file": "proteus_v0.3_q6p_q8p.ckpt",
      "text_encoder": "proteus_v0.3_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "name": "Qwen Image 1.0 (BF16, Exact)",
      "version": "qwen_image",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "qwen_image_1.0_bf16.ckpt",
      "upcast_attention": false,
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "is_bf16": true,
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. The BF16 version is only compatible with macOS 15, iOS 18 and above."
    },
    {
      "name": "Qwen Image 1.0 (Exact)",
      "version": "qwen_image",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "qwen_image_1.0_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[Qwen Image](https://huggingface.co/Qwen/Qwen-Image) is a state-of-the-art open-source image generation model known for its exceptional text layout and prompt adherence across a wide range of styles, including photorealistic, cartoon, and artistic. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended."
    },
    {
      "name": "Qwen Image Edit 2509 (BF16, Exact)",
      "version": "qwen_image",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "qwen_image_edit_2509_bf16.ckpt",
      "upcast_attention": false,
      "modifier": "qwenimage_edit_plus",
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "clip_encoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "is_bf16": true,
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. This is an update in Sep, 2025. The BF16 version is only compatible with macOS 15, iOS 18 and above."
    },
    {
      "name": "Qwen Image Edit 2509 (Exact)",
      "version": "qwen_image",
      "autoencoder": "qwen_image_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "qwen_image_edit_2509_f16.ckpt",
      "upcast_attention": false,
      "modifier": "qwenimage_edit_plus",
      "text_encoder": "qwen_2.5_vl_7b_f16.ckpt",
      "clip_encoder": "qwen_2.5_vl_7b_vit_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[Qwen Image Edit 2509](https://huggingface.co/Qwen/Qwen-Image-2509) is a state-of-the-art open-source image edit model excels at image edit tasks such as background alternation, style transfer, object removal etc. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 30–50 sampling steps recommended. This is an update in Sep, 2025."
    },
    {
      "name": "RayFLUX v3.0",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "rayflux_v3.0_aio_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "name": "RayFLUX v3.0 (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "rayflux_v3.0_aio_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ]
    },
    {
      "version": "v1",
      "default_scale": 12,
      "prefix": "",
      "name": "Realistic Vision v5.1",
      "upcast_attention": false,
      "text_encoder": "realistic_vision_v5.1_clip_vit_l14_f16.ckpt",
      "file": "realistic_vision_v5.1_f16.ckpt",
      "modifier": "none"
    },
    {
      "version": "v1",
      "default_scale": 12,
      "prefix": "",
      "name": "Realistic Vision v5.1 (8-bit)",
      "upcast_attention": false,
      "text_encoder": "realistic_vision_v5.1_clip_vit_l14_f16.ckpt",
      "file": "realistic_vision_v5.1_q6p_q8p.ckpt",
      "modifier": "none"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "RealVisXL v4.0",
      "modifier": "none",
      "clip_encoder": "realvisxl_v4.0_clip_vit_l14_f16.ckpt",
      "text_encoder": "realvisxl_v4.0_open_clip_vit_bigg14_f16.ckpt",
      "file": "realvisxl_v4.0_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "RealVisXL v4.0 (8-bit)",
      "modifier": "none",
      "clip_encoder": "realvisxl_v4.0_clip_vit_l14_f16.ckpt",
      "text_encoder": "realvisxl_v4.0_open_clip_vit_bigg14_f16.ckpt",
      "file": "realvisxl_v4.0_q6p_q8p.ckpt"
    },
    {
      "version": "v1",
      "default_scale": 8,
      "prefix": "",
      "name": "Rev Animated v1.22",
      "upcast_attention": false,
      "modifier": "none",
      "text_encoder": "rev_animated_v1.22_clip_vit_l14_f16.ckpt",
      "file": "rev_animated_v1.22_f16.ckpt"
    },
    {
      "version": "v1",
      "default_scale": 8,
      "prefix": "",
      "name": "Rev Animated v1.22 (8-bit)",
      "upcast_attention": false,
      "modifier": "none",
      "text_encoder": "rev_animated_v1.22_clip_vit_l14_f16.ckpt",
      "file": "rev_animated_v1.22_q6p_q8p.ckpt"
    },
    {
      "version": "v1",
      "name": "SamDoesArt (v3)",
      "upcast_attention": false,
      "text_encoder": "samdoesart_v3_clip_vit_l14_f16.ckpt",
      "default_scale": 8,
      "prefix": "samdoesart ",
      "file": "samdoesart_v3_f16.ckpt"
    },
    {
      "name": "schnellMODE v3.3",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "schnellmode_v3.3_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "schnellMODE v3.3 (5-bit, SVDQuant)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "schnellmode_v3.3_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "builtin_lora": true
    },
    {
      "name": "SD3 Large 3.5",
      "version": "sd3_large",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_large_3.5_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "SD3 Large 3.5 (6-bit)",
      "version": "sd3_large",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_large_3.5_q6p.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "SD3 Large 3.5 (Exact)",
      "version": "sd3_large",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_large_3.5_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "SD3 Large Turbo 3.5",
      "version": "sd3_large",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_large_turbo_3.5_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "is_consistency_model": true
    },
    {
      "name": "SD3 Large Turbo 3.5 (6-bit)",
      "version": "sd3_large",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_large_turbo_3.5_q6p.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "is_consistency_model": true
    },
    {
      "name": "SD3 Medium",
      "version": "sd3",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_medium_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "SD3 Medium (8-bit)",
      "version": "sd3",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "sd3_medium_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "SD3 Medium 3.5",
      "version": "sd3",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 32,
      "file": "sd3_medium_3.5_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "qk_norm": true,
        "dual_attention_layers": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
        ]
      }
    },
    {
      "name": "SD3 Medium 3.5 (8-bit)",
      "version": "sd3",
      "autoencoder": "sd3_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "t5_encoder": "t5_xxl_encoder_q6p.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 32,
      "file": "sd3_medium_3.5_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "qk_norm": true,
        "dual_attention_layers": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
        ]
      }
    },
    {
      "name": "SDXL Turbo",
      "prefix": "",
      "default_scale": 8,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "file": "sd_xl_turbo_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "is_consistency_model": true
    },
    {
      "name": "SDXL Turbo (8-bit)",
      "prefix": "",
      "default_scale": 8,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "file": "sd_xl_turbo_q6p_q8p.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "is_consistency_model": true
    },
    {
      "text_encoder": "seek_art_mega_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "name": "seek.art MEGA (v1)",
      "version": "v1",
      "file": "seek_art_mega_v1_f16.ckpt",
      "default_scale": 10,
      "prefix": ""
    },
    {
      "name": "Shuttle Jaguar",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "shuttle_jaguar_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "Shuttle Jaguar (5-bit, SVDQuant)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "shuttle_jaguar_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "builtin_lora": true
    },
    {
      "name": "Shuttle v3.1 Aesthetic",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "shuttle_v3.1_aesthetic_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      }
    },
    {
      "name": "Shuttle v3.1 Aesthetic (5-bit, SVDQuant)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "shuttle_v3.1_aesthetic_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "is_consistency_model": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "builtin_lora": true
    },
    {
      "name": "SkyReels v1 Hunyuan I2V 544p",
      "version": "hunyuan_video",
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "prefix": "FPS-24, ",
      "default_scale": 12,
      "hires_fix_scale": 24,
      "file": "skyreels_v1_hunyuan_i2v_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": false,
      "modifier": "inpainting",
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        733.226126,
        -401.131952,
        67.5869174,
        -3.149878,
        0.0961237896
      ],
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent’s state-of-the-art text-to-video model. SkyReels v1 I2V is an image-to-video (img2vid) fine-tune that generates video clips up to 4 seconds long from a single image. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6."
    },
    {
      "name": "SkyReels v1 Hunyuan I2V 544p (5-bit, SVDQuant)",
      "version": "hunyuan_video",
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "prefix": "FPS-24, ",
      "default_scale": 12,
      "hires_fix_scale": 24,
      "file": "skyreels_v1_hunyuan_i2v_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": false,
      "modifier": "inpainting",
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        733.226126,
        -401.131952,
        67.5869174,
        -3.149878,
        0.0961237896
      ],
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent’s state-of-the-art text-to-video model. SkyReels v1 I2V is an image-to-video (img2vid) fine-tune that generates video clips up to 4 seconds long from a single image. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6.",
      "builtin_lora": true
    },
    {
      "name": "SkyReels v1 Hunyuan T2V 544p",
      "version": "hunyuan_video",
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "prefix": "FPS-24, ",
      "default_scale": 12,
      "hires_fix_scale": 24,
      "file": "skyreels_v1_hunyuan_t2v_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": false,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        733.226126,
        -401.131952,
        67.5869174,
        -3.149878,
        0.0961237896
      ],
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent’s state-of-the-art text-to-video model. It can generate video clips up to 4 seconds long at a recommended resolution of 960×544. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6."
    },
    {
      "name": "SkyReels v1 Hunyuan T2V 544p (5-bit, SVDQuant)",
      "version": "hunyuan_video",
      "autoencoder": "hunyuan_video_vae_f16.ckpt",
      "prefix": "FPS-24, ",
      "default_scale": 12,
      "hires_fix_scale": 24,
      "file": "skyreels_v1_hunyuan_t2v_q5p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "llava_llama_3_8b_v1.1_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": false,
      "guidance_embed": true,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        733.226126,
        -401.131952,
        67.5869174,
        -3.149878,
        0.0961237896
      ],
      "note": "[SkyReels v1](https://huggingface.co/collections/Skywork/skyreels-v1-67b34676ff65b4ec02d16307) is a significant fine-tune of Hunyuan Video, Tencent’s state-of-the-art text-to-video model. It can generate video clips up to 4 seconds long at a recommended resolution of 960×544. The model supports up to 97 frames, with a recommended shift value of 7.0 or higher. For optimal results, disable \"Speedup w/ Guidance Embed\" by setting it to 1.0 and use a Text Guidance value of 6.",
      "builtin_lora": true
    },
    {
      "name": "SkyReels v2 I2V 1.3B 540p",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "hires_fix_scale": 12,
      "file": "skyreels_v2_i2v_1.3b_540p_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[SkyReels v2 I2V 1.3B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (1.3B), it performs best with similar generation settings."
    },
    {
      "name": "SkyReels v2 I2V 1.3B 540p (8-bit)",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "hires_fix_scale": 12,
      "file": "skyreels_v2_i2v_1.3b_540p_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[SkyReels v2 I2V 1.3B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (1.3B), it performs best with similar generation settings."
    },
    {
      "name": "SkyReels v2 I2V 14B 540p",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_i2v_14b_540p_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[SkyReels v2 I2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings."
    },
    {
      "name": "SkyReels v2 I2V 14B 540p (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_i2v_14b_540p_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        257151.496,
        -35422.9917,
        1402.86849,
        -13.5890334,
        0.132517977
      ],
      "note": "[SkyReels v2 I2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "builtin_lora": true
    },
    {
      "name": "SkyReels v2 I2V 14B 720p",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_i2v_14b_720p_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[SkyReels v2 I2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings."
    },
    {
      "name": "SkyReels v2 I2V 14B 720p (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_i2v_14b_720p_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[SkyReels v2 I2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P) is a image-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "builtin_lora": true
    },
    {
      "name": "SkyReels v2 T2V 14B 540p",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_t2v_14b_540p_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[SkyReels v2 T2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings."
    },
    {
      "name": "SkyReels v2 T2V 14B 540p (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_t2v_14b_540p_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[SkyReels v2 T2V 14B 540p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 4 seconds in length. The model is trained at 544x960, supports up to 97 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "builtin_lora": true
    },
    {
      "name": "SkyReels v2 T2V 14B 720p",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_t2v_14b_720p_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[SkyReels v2 T2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings."
    },
    {
      "name": "SkyReels v2 T2V 14B 720p (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "skyreels_v2_t2v_14b_720p_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 24,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[SkyReels v2 T2V 14B 720p](https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P) is a text-to-video model developed by Skywork AI. It can generate video clips of up to 5 seconds in length. The model is trained at 720x1280, supports up to 121 frames, with a recommended shift value of 5.0. As a derivative of Wan 2.1 (14B), it performs best with similar generation settings.",
      "builtin_lora": true
    },
    {
      "name": "Spider-Verse (v1)",
      "version": "v1",
      "text_encoder": "spiderverse_v1_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 8,
      "file": "spiderverse_v1_f16.ckpt",
      "prefix": "spiderverse style "
    },
    {
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "file": "ssd_1b_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "version": "ssd_1b",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "name": "SSD 1B (Segmind SDXL)",
      "default_scale": 16
    },
    {
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "file": "ssd_1b_q6p_q8p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "version": "ssd_1b",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "name": "SSD 1B (Segmind SDXL) (8-bit)",
      "default_scale": 16
    },
    {
      "name": "Stable Cascade (Würstchen v3.0)",
      "stage_models": [
        "wurstchen_3.0_stage_b_f16.ckpt"
      ],
      "version": "wurstchen_v3.0_stage_c",
      "default_scale": 16,
      "file": "wurstchen_3.0_stage_c_f32_f16.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "wurstchen_3.0_stage_a_hq_f16.ckpt",
      "upcast_attention": false,
      "prefix": ""
    },
    {
      "name": "Stable Cascade (Würstchen v3.0) (8-bit)",
      "stage_models": [
        "wurstchen_3.0_stage_b_q6p_q8p.ckpt"
      ],
      "version": "wurstchen_v3.0_stage_c",
      "default_scale": 16,
      "file": "wurstchen_3.0_stage_c_f32_q6p_q8p.ckpt",
      "text_encoder": "open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "wurstchen_3.0_stage_a_hq_f16.ckpt",
      "upcast_attention": false,
      "prefix": ""
    },
    {
      "file": "svd_i2v_1.0_f16.ckpt",
      "version": "svd_i2v",
      "conditioning": "noise",
      "objective": {
        "v": {}
      },
      "prefix": "",
      "default_scale": 8,
      "clip_encoder": "svd_i2v_1.0_f16.ckpt",
      "name": "Stable Video Diffusion I2V v1.0",
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_max": 700,
            "sigma_data": 0.5,
            "sigma_min": 0.002
          }
        }
      }
    },
    {
      "file": "svd_i2v_1.0_q6p_q8p.ckpt",
      "version": "svd_i2v",
      "conditioning": "noise",
      "objective": {
        "v": {}
      },
      "prefix": "",
      "default_scale": 8,
      "clip_encoder": "svd_i2v_1.0_q6p_q8p.ckpt",
      "name": "Stable Video Diffusion I2V v1.0 (8-bit)",
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_max": 700,
            "sigma_data": 0.5,
            "sigma_min": 0.002
          }
        }
      }
    },
    {
      "file": "svd_i2v_xt_1.1_f16.ckpt",
      "version": "svd_i2v",
      "conditioning": "noise",
      "objective": {
        "v": {}
      },
      "prefix": "",
      "default_scale": 8,
      "clip_encoder": "svd_i2v_xt_1.1_f16.ckpt",
      "name": "Stable Video Diffusion I2V XT v1.1",
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_max": 700,
            "sigma_data": 0.5,
            "sigma_min": 0.002
          }
        }
      }
    },
    {
      "file": "svd_i2v_xt_1.1_q6p_q8p.ckpt",
      "version": "svd_i2v",
      "conditioning": "noise",
      "objective": {
        "v": {}
      },
      "prefix": "",
      "default_scale": 8,
      "clip_encoder": "svd_i2v_xt_1.1_q6p_q8p.ckpt",
      "name": "Stable Video Diffusion I2V XT v1.1 (8-bit)",
      "text_encoder": "open_clip_vit_h14_vision_model_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none",
      "noise_discretization": {
        "edm": {
          "_0": {
            "sigma_max": 700,
            "sigma_data": 0.5,
            "sigma_min": 0.002
          }
        }
      }
    },
    {
      "name": "Super Mario Nation (v2)",
      "default_scale": 8,
      "text_encoder": "supermarionation_v2_clip_vit_l14_f16.ckpt",
      "file": "supermarionation_v2_f16.ckpt",
      "prefix": "supermarionation ",
      "version": "v1",
      "upcast_attention": false
    },
    {
      "version": "v1",
      "prefix": "trnlgcy style ",
      "upcast_attention": false,
      "default_scale": 8,
      "text_encoder": "trnlgcy_clip_vit_l14_f16.ckpt",
      "name": "Tron Legacy",
      "file": "trnlgcy_f16.ckpt"
    },
    {
      "name": "Van Gogh Style (Lvngvncnt v2)",
      "version": "v1",
      "text_encoder": "lvngvncnt_v2_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 8,
      "file": "lvngvncnt_v2_f16.ckpt",
      "prefix": "lvngvncnt "
    },
    {
      "name": "VoxelArt (v1)",
      "upcast_attention": false,
      "version": "v1",
      "file": "voxelart_v1_f16.ckpt",
      "prefix": "voxelart ",
      "default_scale": 8,
      "text_encoder": "voxelart_v1_clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Wan 2.1 1.3B Fun InP",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "hires_fix_scale": 12,
      "file": "wan_2.1_1.3b_fun_inp_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -52186.2437,
        9230.41404,
        -528.275948,
        13.6987616,
        -0.0499875664
      ],
      "note": "[Wan2.1 1.3B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result."
    },
    {
      "name": "Wan 2.1 1.3B Fun InP (8-bit)",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "hires_fix_scale": 12,
      "file": "wan_2.1_1.3b_fun_inp_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -52186.2437,
        9230.41404,
        -528.275948,
        13.6987616,
        -0.0499875664
      ],
      "note": "[Wan2.1 1.3B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result."
    },
    {
      "name": "Wan 2.1 1.3B v1.1 Fun InP",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "hires_fix_scale": 12,
      "file": "wan_2.1_1.3b_v1.1_fun_inp_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -52186.2437,
        9230.41404,
        -528.275948,
        13.6987616,
        -0.0499875664
      ],
      "note": "[Wan2.1 1.3B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result."
    },
    {
      "name": "Wan 2.1 1.3B v1.1 Fun InP (8-bit)",
      "version": "wan_v2.1_1.3b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 8,
      "hires_fix_scale": 12,
      "file": "wan_2.1_1.3b_v1.1_fun_inp_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -52186.2437,
        9230.41404,
        -528.275948,
        13.6987616,
        -0.0499875664
      ],
      "note": "[Wan2.1 1.3B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result."
    },
    {
      "name": "Wan 2.1 14B Fun InP",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_fun_inp_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[Wan2.1 14B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result."
    },
    {
      "name": "Wan 2.1 14B Fun InP (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_fun_inp_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[Wan2.1 14B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "builtin_lora": true
    },
    {
      "name": "Wan 2.1 14B I2V FusionX",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_i2v_fusionx_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs."
    },
    {
      "name": "Wan 2.1 14B I2V FusionX (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_i2v_fusionx_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs.",
      "builtin_lora": true
    },
    {
      "name": "Wan 2.1 14B T2V FusionX",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_t2v_fusionx_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs."
    },
    {
      "name": "Wan 2.1 14B T2V FusionX (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_t2v_fusionx_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[Wan2.1 14B FusionX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX) is a merged model of multiple quality and acceleration LoRAs.",
      "builtin_lora": true
    },
    {
      "name": "Wan 2.1 14B v1.1 Fun InP",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_v1.1_fun_inp_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[Wan2.1 14B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result."
    },
    {
      "name": "Wan 2.1 14B v1.1 Fun InP (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_2.1_14b_v1.1_fun_inp_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[Wan2.1 14B v1.1 Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-V1.1-14B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
      "builtin_lora": true
    },
    {
      "name": "Wan v2.2 High Noise Expert T2V A14B Lightning 250928",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_v2.2_a14b_hne_t2v_lightning_250928_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[Wan2.2 High Noise Expert T2V A14B Lightning 250928](https://huggingface.co/lightx2v/Wan2.2-Lightning/tree/main/Wan2.2-T2V-A14B-4steps-250928-dyno) is a fine-tune of Wan v2.2 High Noise Expert model. It can generate more dynamic motions with 4 steps and text guidance 1.0."
    },
    {
      "name": "Wan v2.2 High Noise Expert T2V A14B Lightning 250928 (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "wan_v2.2_a14b_hne_t2v_lightning_250928_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        -303318.725,
        49053.7029,
        -2655.30556,
        58.7365115,
        -0.315583525
      ],
      "note": "[Wan2.2 High Noise Expert T2V A14B Lightning 250928](https://huggingface.co/lightx2v/Wan2.2-Lightning/tree/main/Wan2.2-T2V-A14B-4steps-250928-dyno) is a fine-tune of Wan v2.2 High Noise Expert model. It can generate more dynamic motions with 4 steps and text guidance 1.0.",
      "builtin_lora": true
    },
    {
      "name": "Z Image Turbo 1.0 (Exact)",
      "version": "z_image",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "z_image_turbo_1.0_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "qwen_3_vl_4b_instruct_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "note": "[Z Image Turbo](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo) is is a powerful and highly efficient image generation model with 6B parameters. It is Apache 2.0-licensed and commercially friendly. The model is trained at multiple resolutions using a Flow Matching objective; trailing samplers yield the best results, with 8 sampling steps recommended."
    }
  ],
  "communityCnets": [
    {
      "version": "flux1",
      "file": "controlnet_alimama_inpaint_flux_1_dev_beta_q8p.ckpt",
      "name": "Alimam Inpaint Beta (FLUX.1 [dev], ControlNet)",
      "global_average_pooling": false,
      "transformer_blocks": [
        6,
        0
      ],
      "type": "controlnet",
      "modifier": "inpaint"
    },
    {
      "version": "flux1",
      "file": "controlnet_alimama_inpaint_flux_1_dev_beta_q6p.ckpt",
      "name": "Alimam Inpaint Beta (FLUX.1 [dev], ControlNet) (6-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [
        6,
        0
      ],
      "type": "controlnet",
      "modifier": "inpaint"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_canny_kwai_kolors_1.0_f16.ckpt",
      "modifier": "canny",
      "name": "Canny Edge Map (Kwai Kolors 1.0)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnet"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_canny_kwai_kolors_1.0_q6p_q8p.ckpt",
      "modifier": "canny",
      "name": "Canny Edge Map (Kwai Kolors 1.0) (8-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnet"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_depth_kwai_kolors_1.0_f16.ckpt",
      "modifier": "depth",
      "name": "Depth Map (Kwai Kolors 1.0)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnet"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_depth_kwai_kolors_1.0_q6p_q8p.ckpt",
      "modifier": "depth",
      "name": "Depth Map (Kwai Kolors 1.0) (8-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnet"
    },
    {
      "version": "flux1",
      "file": "flex_1_redux_siglip2_512_f16.ckpt",
      "modifier": "shuffle",
      "name": "FLEX.1 Redux SigLIP2 512 (FLUX.1)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "redux",
      "image_encoder": "siglip2_so400m_512_f16.ckpt",
      "image_encoder_version": "siglip2_l27_512"
    },
    {
      "version": "flux1",
      "file": "flux_1_redux_f16.ckpt",
      "modifier": "shuffle",
      "name": "FLUX.1 Redux (FLUX.1)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "redux",
      "image_encoder": "siglip_so400m_384_f16.ckpt",
      "image_encoder_version": "siglip_l27_384"
    },
    {
      "version": "v1",
      "file": "ootd_garm_full_body_1.0_f16.ckpt",
      "modifier": "shuffle",
      "name": "Garment UNet (Full-Body, Outfitting Fusion)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "inject_kv",
      "image_encoder": "clip_vit_l14_vision_model_f16.ckpt",
      "autoencoder": "vae_ft_mse_840000_f16.ckpt"
    },
    {
      "version": "v1",
      "file": "ootd_garm_upper_body_1.0_f16.ckpt",
      "modifier": "shuffle",
      "name": "Garment UNet (Upper-Body, Outfitting Fusion)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "inject_kv",
      "image_encoder": "clip_vit_l14_vision_model_f16.ckpt",
      "autoencoder": "vae_ft_mse_840000_f16.ckpt"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "ip_adapter_faceid_plus_kwai_kolors_1.0_clip_l14_336_f16.ckpt",
      "modifier": "shuffle",
      "name": "IP Adapter FaceID Plus (Kwai Kolors 1.0)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "ipadapterfaceidplus",
      "image_encoder": "clip_vit_l14_336_vision_model_f16.ckpt",
      "image_encoder_version": "clip_l14_336",
      "preprocessor": "arcface_f16.ckpt",
      "ip_adapter_config": {
        "input_dim": 4096,
        "query_dim": 4096,
        "output_dim": 4096,
        "head_dim": 64,
        "num_heads": 64,
        "grid": 24
      }
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "ip_adapter_faceid_plus_kwai_kolors_1.0_clip_l14_336_q8p.ckpt",
      "modifier": "shuffle",
      "name": "IP Adapter FaceID Plus (Kwai Kolors 1.0) (8-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "ipadapterfaceidplus",
      "image_encoder": "clip_vit_l14_336_vision_model_f16.ckpt",
      "image_encoder_version": "clip_l14_336",
      "preprocessor": "arcface_f16.ckpt",
      "ip_adapter_config": {
        "input_dim": 4096,
        "query_dim": 4096,
        "output_dim": 4096,
        "head_dim": 64,
        "num_heads": 64,
        "grid": 24
      }
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "ip_adapter_plus_kwai_kolors_1.0_clip_l14_336_f16.ckpt",
      "modifier": "shuffle",
      "name": "IP Adapter Plus (Kwai Kolors 1.0)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "ipadapterplus",
      "image_encoder": "clip_vit_l14_336_vision_model_f16.ckpt",
      "image_encoder_version": "clip_l14_336",
      "ip_adapter_config": {
        "input_dim": 2048,
        "query_dim": 2048,
        "output_dim": 2048,
        "head_dim": 64,
        "num_heads": 12,
        "grid": 24
      }
    },
    {
      "version": "flux1",
      "file": "controlnet_jasper_ai_upscaler_flux_1_dev_1.0_f16.ckpt",
      "name": "Jasper AI Upscaler (FLUX.1 [dev], ControlNet)",
      "global_average_pooling": false,
      "transformer_blocks": [
        5,
        0
      ],
      "type": "controlnet",
      "modifier": "tile"
    },
    {
      "version": "hunyuan_video",
      "file": "llava_llama_3_8b_v1.1_multi_modal_projector_f16.ckpt",
      "modifier": "shuffle",
      "name": "LLaVA Image Prompt (Hunyuan Video)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "llava",
      "image_encoder": "clip_vit_l14_336_vision_model_f16.ckpt",
      "image_encoder_version": "clip_l14_336"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_pose_kwai_kolors_1.0_f16.ckpt",
      "modifier": "pose",
      "name": "Pose (Kwai Kolors 1.0)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnet"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_pose_kwai_kolors_1.0_q6p_q8p.ckpt",
      "modifier": "pose",
      "name": "Pose (Kwai Kolors 1.0) (8-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnet"
    },
    {
      "version": "flux1",
      "file": "pulid_0.9.1_eva02_clip_l14_336_f16.ckpt",
      "modifier": "shuffle",
      "name": "PuLID 0.9.1 (FLUX.1 [dev])",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "pulid",
      "image_encoder": "eva02_clip_l14_336_f16.ckpt",
      "image_encoder_version": "eva02_l14_336",
      "preprocessor": "arcface_f16.ckpt",
      "ip_adapter_config": {
        "input_dim": 1024,
        "query_dim": 1024,
        "output_dim": 2048,
        "head_dim": 64,
        "num_heads": 16,
        "grid": 24
      }
    },
    {
      "version": "flux1",
      "file": "controlnet_union_pro_flux_1_dev_1.0_q8p.ckpt",
      "name": "Union Pro (FLUX.1 [dev], ControlNet)",
      "global_average_pooling": false,
      "transformer_blocks": [
        5,
        10
      ],
      "type": "controlnetunion"
    },
    {
      "version": "flux1",
      "file": "controlnet_union_pro_flux_1_dev_1.0_q5p.ckpt",
      "name": "Union Pro (FLUX.1 [dev], ControlNet) (5-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [
        5,
        10
      ],
      "type": "controlnetunion"
    },
    {
      "version": "flux1",
      "file": "controlnet_union_pro_flux_1_dev_2.0_q8p.ckpt",
      "name": "Union Pro 2.0 (FLUX.1 [dev], ControlNet)",
      "global_average_pooling": false,
      "transformer_blocks": [
        6,
        0
      ],
      "type": "controlnet"
    },
    {
      "version": "flux1",
      "file": "controlnet_union_pro_flux_1_dev_2.0_q5p.ckpt",
      "name": "Union Pro 2.0 (FLUX.1 [dev], ControlNet) (5-bit)",
      "global_average_pooling": false,
      "transformer_blocks": [
        6,
        0
      ],
      "type": "controlnet"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "controlnet_xinsir_union_promax_sdxl_1.0_f16.ckpt",
      "name": "Xinsir Union ProMax (SDXL, ControlNet)",
      "global_average_pooling": false,
      "transformer_blocks": [],
      "type": "controlnetunion"
    }
  ],
  "communityLoras": [
    {
      "name": "360 Degree [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "360_degree__dev__lora_f16.ckpt"
    },
    {
      "name": "ACE++: Local Editing",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "ace____local_editing_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      },
      "note": "[ACE++](https://huggingface.co/ali-vilab/ACE_Plus) is an effective transfer method that fine-tunes FLUX.1 Fill [dev] model. This LoRA enables sketch-to-image for the masked area."
    },
    {
      "name": "ACE++: Portrait",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "ace____portrait_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      },
      "note": "[ACE++](https://huggingface.co/ali-vilab/ACE_Plus) is an effective transfer method that fine-tunes FLUX.1 Fill [dev] model. The reference image is placed on the left, while the right side is either the image to edit or left blank. The model uses the left-side reference image during generation. This LoRA enables the transfer of a person's identity to a new image."
    },
    {
      "name": "ACE++: Subject",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "ace____subject_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      },
      "note": "[ACE++](https://huggingface.co/ali-vilab/ACE_Plus) is an effective transfer method that fine-tunes FLUX.1 Fill [dev] model. The reference image is placed on the left, while the right side is either the image to edit or left blank. The model uses the left-side reference image during generation. This LoRA enables the transfer of a subject (such as a logo) to a new image."
    },
    {
      "name": "Adam's Artwork Style v.1",
      "file": "adams_artwork_style_v0.1_lora_f16.ckpt",
      "prefix": "ajaws ",
      "version": "v1"
    },
    {
      "version": "v1",
      "name": "Add More Details (Detail Enhancer / Tweaker)",
      "prefix": "",
      "is_lo_ha": false,
      "file": "add_more_details__detail_enhancer___tweaker__lora_f16.ckpt"
    },
    {
      "name": "Age Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "age_slider_lora_f16.ckpt"
    },
    {
      "name": "Amateur Photography v3.5 [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "amateur_photography_v3.5__dev__lora_f16.ckpt"
    },
    {
      "name": "Analog Diffusion v1.0",
      "file": "analog_diffusion_v1_lora_f16.ckpt",
      "prefix": "analog ",
      "version": "v1"
    },
    {
      "name": "Anime LineArt Style v2.0",
      "file": "anime_lineart_style_v2.0_lora_f16.ckpt",
      "prefix": "",
      "version": "v1"
    },
    {
      "name": "AntiBlur v1.0 [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "antiblur_v1.0__dev__lora_f16.ckpt"
    },
    {
      "version": "v1",
      "file": "arcane_style_lora_f16.ckpt",
      "prefix": "arcane style ",
      "name": "Arcane Style"
    },
    {
      "name": "Boring Reality v2 [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "boring_reality_v2_lora_f16.ckpt"
    },
    {
      "name": "CCXL-Mucha Art Style",
      "file": "ccxl_mucha_art_style_lora_f16.ckpt",
      "prefix": "ccxl-mucha ",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "ChronoEdit 14B Step Distill",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "chronoedit_14b_step_distill_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "ChronoEdit 14B Upsample",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "chronoedit_14b_upsample_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "version": "v1",
      "file": "crazy_expressions_lora_f16.ckpt",
      "prefix": "crazy face ",
      "name": "Crazy Expressions"
    },
    {
      "name": "Cyberpunk 2077 Nightcity v1.15",
      "file": "cyberpunk_2007_concept_art_nightcity_v1.15_lora_f16.ckpt",
      "prefix": "",
      "version": "v1"
    },
    {
      "name": "DMD2 SDXL 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "dmd2_sdxl_4_step_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Epi Noise Offset v2",
      "file": "epi_noiseoffset_v2_lora_f16.ckpt",
      "prefix": "",
      "version": "v1"
    },
    {
      "name": "Fix Hands Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "fix_hands_slider_lora_f16.ckpt"
    },
    {
      "name": "FLUX.1 [dev] to [schnell] 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "flux.1__dev__to__schnell__4_step_lora_f16.ckpt"
    },
    {
      "name": "FLUX.1 Canny [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "flux_1_canny_dev_lora_f16.ckpt",
      "modifier": "canny",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "FLUX.1 Depth [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "flux_1_depth_dev_lora_f16.ckpt",
      "modifier": "depth",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "FLUX.1 Turbo Alpha",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "flux.1_turbo_alpha_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Ghibli Cartoon Art",
      "prefix": "Ghibli Art",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "ghibli_cartoon_art_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "version": "v1",
      "file": "haute_couture_or_gowns_v1.0_lora_f16.ckpt",
      "prefix": "hc_gown ",
      "name": "Haute Couture or Gowns v1.0"
    },
    {
      "name": "HiDream E1",
      "prefix": "",
      "is_lo_ha": false,
      "version": "hidream_i1",
      "modifier": "editing",
      "file": "hidream_e1_full_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "version": "v1",
      "file": "hipoly_3d_model_lora_f16.ckpt",
      "prefix": "hiqcgbody ",
      "name": "Hipoly 3D Model"
    },
    {
      "name": "Hyper FLUX.1 [dev] 16-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "hyper_flux.1__dev__16_step_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Hyper FLUX.1 [dev] 8-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "hyper_flux.1__dev__8_step_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Hyper SD v1.x 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "v1",
      "is_consistency_model": true,
      "file": "hyper_sd_v1.x_4_step_lora_f16.ckpt"
    },
    {
      "name": "Hyper SD v1.x 8-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "v1",
      "is_consistency_model": true,
      "file": "hyper_sd_v1.x_8_step_lora_f16.ckpt"
    },
    {
      "name": "Hyper SD3 16-Step CFG",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sd3",
      "file": "hyper_sd3_16_step_cfg_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Hyper SD3 4-Step CFG",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sd3",
      "file": "hyper_sd3_4_step_cfg_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Hyper SD3 8-Step CFG",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sd3",
      "file": "hyper_sd3_8_step_cfg_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Hyper SDXL 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true,
      "file": "hyper_sdxl_4_step_lora_f16.ckpt"
    },
    {
      "name": "Hyper SDXL 8-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true,
      "file": "hyper_sdxl_8_step_lora_f16.ckpt"
    },
    {
      "name": "ICEdit Normal",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "icedit_normal_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      },
      "note": "[ICEdit](https://huggingface.co/RiverZ/normal-lora) is an efficient and effective method for instruction-based image editing. With only 1% trainable parameters (200M) and 0.1% training data (50k) compared to previous methods, ICEdit demonstrates strong generalization capabilities and is capable of handling diverse editing tasks. The model uses the left-side reference image during generation."
    },
    {
      "name": "In-Context: Couple Profile",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__couple_profile_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: Film Storyboard",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__film_storyboard_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: Font Design",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__font_design_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: Home Decoration",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__home_decoration_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: Portrait Illustration",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__portrait_illustration_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: Portrait Photography",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__portrait_photography_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: PPT Templates",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__ppt_templates_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "In-Context: Visual Identity Design",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "in_context__visual_identity_design_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "version": "ssd_1b",
      "file": "lcm_ssd_1b_lora_f16.ckpt",
      "prefix": "",
      "name": "LCM SSD 1B (Segmind)"
    },
    {
      "name": "Long Hair Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "long_hair_slider_lora_f16.ckpt"
    },
    {
      "name": "Mascular Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "mascular_slider_lora_f16.ckpt"
    },
    {
      "version": "v1",
      "name": "Moxin Shukezouma v1.1",
      "prefix": "shukezouma ",
      "file": "moxin_shukezouma_v1.1_lora_f16.ckpt"
    },
    {
      "version": "v1",
      "file": "moxin_v1.0_lora_f16.ckpt",
      "name": "Moxin v1.0",
      "prefix": "shuimobysim "
    },
    {
      "name": "Object Removal for FLUX.1 Fill v2",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "object_removal_for_flux.1_fill_v2_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      },
      "note": "This is an Object Removal LoRA fine-tuned from Flux Fill Dev model by [lrzjason](https://huggingface.co/lrzjason). The lora is designed to remove objects from specified masked areas, making it useful for image editing tasks where unwanted objects need to be erased seamlessly."
    },
    {
      "name": "Openjourney v1.0",
      "file": "openjourney_v1_lora_f16.ckpt",
      "prefix": "mdjrny-v4 ",
      "version": "v1"
    },
    {
      "name": "Papercut SDXL",
      "prefix": "papercut ",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "papercut_sdxl_lora_f16.ckpt"
    },
    {
      "name": "PCM SD3 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sd3",
      "file": "pcm_sd3_4_step_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Pixel Art XL v1.1",
      "prefix": "",
      "is_lo_ha": false,
      "file": "pixel_art_xl_v1.1_lora_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Pony: People’s Works v8_Illusv 2.0 Stable",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "pony__people_s_works_v8_illusv_2.0_stable_lora_f16.ckpt"
    },
    {
      "name": "Qwen Edit 2509 Anything2Real",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_edit_2509_anything2real_lora_f16.ckpt",
      "weight": {
        "value": 0.9,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Edit 2509 Fusion",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_edit_2509_fusion_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Edit 2509 Multiple Angles",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_edit_2509_multiple_angles_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Edit 2509 Relight",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_edit_2509_relight_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Edit 2509 White to Scene",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_edit_2509_white_to_scene_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image 1.0 Lightning 4-Step v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_1.0_lightning_4_step_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image 1.0 Lightning 4-Step v2.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_1.0_lightning_4_step_v2.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image 1.0 Lightning 8-Step v1.1",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_1.0_lightning_8_step_v1.1_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image 1.0 Lightning 8-Step v2.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_1.0_lightning_8_step_v2.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image Edit 1.0 Lightning 4-Step v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_edit_1.0_lightning_4_step_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image Edit 1.0 Lightning 8-Step v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_edit_1.0_lightning_8_step_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image Edit 2509 Lightning 4-Step v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_edit_2509_lightning_4_step_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image Edit 2509 Lightning 8-Step v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_edit_2509_lightning_8_step_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Qwen Image Edit 2511 Lightning 4-Step v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "qwen_image",
      "file": "qwen_image_edit_2511_lightning_4_step_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "SD3 Medium 3.5 Turbo 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sd3",
      "file": "sd3_medium_3.5_turbo_4_step_lora_f16.ckpt"
    },
    {
      "name": "SD3 Medium 3.5 Turbo 8-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sd3",
      "file": "sd3_medium_3.5_turbo_8_step_lora_f16.ckpt"
    },
    {
      "name": "SDXL Lightning 4-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true,
      "file": "sdxl_lightning_4_step_lora_f16.ckpt"
    },
    {
      "name": "SDXL Lightning 8-Step",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "is_consistency_model": true,
      "file": "sdxl_lightning_8_step_lora_f16.ckpt"
    },
    {
      "version": "v1",
      "name": "SDXL Render v2.0",
      "prefix": "",
      "is_lo_ha": false,
      "file": "sdxl_render_v2.0_lora_f16.ckpt"
    },
    {
      "name": "Smiling Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "smiling_slider_lora_f16.ckpt"
    },
    {
      "name": "Surprised Look Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "surprised_look_slider_lora_f16.ckpt"
    },
    {
      "version": "v1",
      "file": "theovercomer8s_contrast_fix_lora_f16.ckpt",
      "prefix": "to8contrast style ",
      "name": "Theovercomer8's Contrast Fix"
    },
    {
      "version": "v2",
      "file": "theovercomer8s_contrast_fix_sd_v2.x_lora_f16.ckpt",
      "prefix": "to8contrast style ",
      "name": "Theovercomer8's Contrast Fix"
    },
    {
      "version": "v1",
      "file": "to8s_high_key_lora_f16.ckpt",
      "prefix": "to8highkey ",
      "name": "TO8's High Key"
    },
    {
      "version": "v2",
      "file": "to8s_high_key_sd_v2.x_lora_f16.ckpt",
      "prefix": "to8highkey ",
      "name": "TO8's High Key"
    },
    {
      "name": "Transparent Image FLUX.1 [dev]",
      "prefix": "",
      "is_lo_ha": false,
      "version": "flux1",
      "file": "layer_flux_1_transparent_lora_f16.ckpt",
      "alternative_decoder": "flux_1_transparent_vae_decoder_f16.ckpt",
      "alternative_decoder_version": "transparent",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.1 1.3B CausVid T2V",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_1.3b",
      "file": "wan_2.1_1.3b_causvid_t2v_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.1 1.3B CFG Distill",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_1.3b",
      "is_consistency_model": true,
      "file": "wan_2.1_1.3b_cfg_distill_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.1 14B 480p Self-Forcing I2V",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_2.1_14b_480p_self_forcing_i2v_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.1 14B CausVid T2V",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_2.1_14b_causvid_t2v_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.1 14B Self-Forcing T2V",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_2.1_14b_self_forcing_t2v_v2_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert I2V 251022",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_hne_i2v_lightning_251022_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert I2V v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_hne_i2v_lightning_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert T2V v1.1",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_hne_t2v_lightning_v1.1_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning High Noise Expert T2V v2.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_hne_t2v_lightning_v2.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert I2V 251022",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_lne_i2v_lightning_251022_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert I2V v1.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_lne_i2v_lightning_v1.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert T2V 250928",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_lne_t2v_lightning_250928_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert T2V v1.1",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_lne_t2v_lightning_v1.1_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Wan 2.2 A14B Lightning Low Noise Expert T2V v2.0",
      "prefix": "",
      "is_lo_ha": false,
      "version": "wan_v2.1_14b",
      "file": "wan_v2.2_a14b_lne_t2v_lightning_v2.0_lora_f16.ckpt",
      "weight": {
        "value": 1,
        "lower_bound": -1.5,
        "upper_bound": 2.5
      }
    },
    {
      "name": "Weight Slider",
      "prefix": "",
      "is_lo_ha": false,
      "version": "sdxl_base_v0.9",
      "file": "weight_slider_lora_f16.ckpt"
    }
  ],
  "communityEmbeddings": [
    {
      "keyword": "actionhelper",
      "version": "v2",
      "name": "Action Helper",
      "file": "actionhelper_ti_f16.ckpt",
      "length": 6
    },
    {
      "file": "animescreencap_ti_f16.ckpt",
      "name": "Anime ScreenCap",
      "length": 6,
      "keyword": "animescreencap",
      "version": "v2"
    },
    {
      "file": "bad_prompt_v2_ti_f16.ckpt",
      "keyword": "bad_prompt",
      "version": "v1",
      "name": "Bad Prompt (v2)",
      "length": 8
    },
    {
      "version": "v1",
      "length": 1,
      "keyword": "birb_style",
      "file": "birb_style_ti_f16.ckpt",
      "name": "Birb Style"
    },
    {
      "version": "v2",
      "length": 4,
      "keyword": "carhelper",
      "file": "carhelper_ti_f16.ckpt",
      "name": "Car Helper"
    },
    {
      "keyword": "charturnerv2",
      "version": "v1",
      "name": "Character Turner v2",
      "file": "charturner_v2_ti_f16.ckpt",
      "length": 15
    },
    {
      "version": "v2",
      "name": "Cinema Helper",
      "file": "cinemahelper_ti_f16.ckpt",
      "keyword": "cinemahelper",
      "length": 10
    },
    {
      "version": "v2",
      "name": "Classipeint",
      "file": "classipeint_ti_f16.ckpt",
      "keyword": "classipeint",
      "length": 15
    },
    {
      "version": "v1",
      "length": 4,
      "keyword": "cloudport",
      "file": "cloudport_v1.0_ti_f16.ckpt",
      "name": "Cloudport v1.0"
    },
    {
      "file": "drd_point_e_768_v_ti_f16.ckpt",
      "keyword": "drd_pnte768",
      "name": "Doctor Diffusion's \"Point E\" Negative Embedding",
      "length": 8,
      "version": "v2"
    },
    {
      "version": "v2",
      "name": "Double Exposure",
      "file": "double_exposure_ti_f16.ckpt",
      "keyword": "double_exposure",
      "length": 8
    },
    {
      "keyword": "easynegative",
      "version": "v1",
      "name": "EasyNegative",
      "length": 8,
      "file": "easynegative_ti_f16.ckpt"
    },
    {
      "keyword": "fastnegativev2",
      "version": "v1",
      "name": "Fast Negative",
      "file": "fast_negative_ti_f16.ckpt",
      "length": 67
    },
    {
      "version": "v2",
      "file": "knollingcase_v4_kc16_5000_ti_f16.ckpt",
      "keyword": "kc16_5000",
      "length": 16,
      "name": "Knollingcase (v4)"
    },
    {
      "name": "Laxpeint (v2)",
      "file": "laxpeint_v2_ti_f16.ckpt",
      "keyword": "laxpeintv2",
      "length": 9,
      "version": "v2"
    },
    {
      "keyword": "negativexl_d",
      "name": "NegativeXL",
      "version": "sdxl_base_v0.9",
      "file": "negativexl_ti_f16.ckpt",
      "length": 16
    },
    {
      "file": "parchart_ti_f16.ckpt",
      "keyword": "parchart",
      "version": "v2",
      "length": 10,
      "name": "ParchArt"
    },
    {
      "file": "photohelper_ti_f16.ckpt",
      "keyword": "photohelper",
      "version": "v2",
      "length": 8,
      "name": "Photo Helper"
    },
    {
      "file": "pure_eros_ti_f16.ckpt",
      "keyword": "pure_eros",
      "version": "v1",
      "length": 1,
      "name": "Pure Eros Face"
    },
    {
      "name": "SD2 Papercut",
      "keyword": "sd2_papercut",
      "file": "sd2_papercut_ti_f16.ckpt",
      "length": 8,
      "version": "v2"
    },
    {
      "keyword": "unaestheticxl_alb2",
      "name": "UnaestheticXL Alb2",
      "version": "sdxl_base_v0.9",
      "file": "unaestheticxl_alb2_ti_f16.ckpt",
      "length": 12
    },
    {
      "name": "V2 Dreamink",
      "keyword": "v2_dreamink",
      "file": "v2_dreamink_ti_f16.ckpt",
      "length": 4,
      "version": "v2"
    },
    {
      "name": "Vintage Helper",
      "keyword": "vintagehelper",
      "file": "vintagehelper_ti_f16.ckpt",
      "length": 8,
      "version": "v2"
    }
  ],
  "uncuratedModels": [
    {
      "upcast_attention": false,
      "clip_encoder": "2dn_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "name": "2DN",
      "text_encoder": "2dn_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "file": "2dn_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1693152_8stepscrearthyperflux_creartultimate_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "8Steps_Creart_Hyper_Flux_creart_Ultimate",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "862930_8stepscrearthyperflux_v24hyperdevfp8unet_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "8Steps_Creart_Hyper_Flux_v24Hyper_Dev_Fp8Unet",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "930403_8stepscrearthyperflux_v26hyperdevfp8unet_f16.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "8Steps_Creart_Hyper_Flux_v26Hyper_Dev_Fp8Unet",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "930403_8stepscrearthyperflux_v26hyperdevfp8unet_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "8Steps_Creart_Hyper_Flux_v26Hyper_Dev_Fp8Unet",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1187144_8stepscrearthyperflux_v30hyperdevfp8unet_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "8Steps_Creart_Hyper_Flux_v30Hyper_Dev_Fp8Unet",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1315145_8stepscrearthyperflux_v40hyperdevfp8unet_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "8Steps_Creart_Hyper_Flux_v40Hyper_Dev_Fp8Unet",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "987485_acornisspinningflux_aisfluxdedistilled_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Acorn_Is_Spinning_FLUX_ais_Flux_De_Distilled",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1374658_acornisspinningflux_aisfluxv15_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Acorn_Is_Spinning_FLUX_ais_Flux_V15",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1450688_acornisspinningflux_aisfdedistilledv15_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Acorn_Is_Spinning_FLUX_aisf_De_Distilled_V15",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1298942_acornisspinningflux_aisfhyper8stepv15_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Acorn_Is_Spinning_FLUX_aisf_Hyper8Step_V15",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1656743_acornisspinningflux_aisfv169_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Acorn_Is_Spinning_FLUX_aisf_V169",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1052470_acornisspinningflux_aisf11h8stpchinfx_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Acorn_Is_Spinning_FLUX_aisf11H8stp_Chinfx",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1095910_agfluxfillnsfwfp8_agfluxfillnsfwv17fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "inpainting",
      "name": "Agflux_Fill_NSFWFp8_agflux_Fill_NSFWV17Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "884843_agflux_schnellv10fp8_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Agflux_Schnell_V10Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "864441_agflux_v10fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Agflux_V10Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1055211_agflux_v21fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Agflux_V21Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1244250_agflux_v3fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Agflux_V3Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "agga_s_utopia__illustrious_sdxl_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "text_encoder": "agga_s_utopia__illustrious_sdxl_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "name": "AGGAs-Utopia-_illustrious-SDXL",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "clip_encoder": "agga_s_utopia__illustrious_sdxl_clip_vit_l14_f16.ckpt"
    },
    {
      "file": "amanatsu_illustrious_f16.ckpt",
      "clip_encoder": "amanatsu_illustrious_clip_vit_l14_f16.ckpt",
      "text_encoder": "amanatsu_illustrious_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "name": "Amanatsu-Illustrious",
      "default_scale": 16
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "text_encoder": "anillustrious_open_clip_vit_bigg14_f16.ckpt",
      "name": "Anillustrious",
      "file": "anillustrious_f16.ckpt",
      "clip_encoder": "anillustrious_clip_vit_l14_f16.ckpt"
    },
    {
      "modifier": "none",
      "text_encoder": "animij_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "file": "animij_f16.ckpt",
      "prefix": "",
      "name": "Animij",
      "clip_encoder": "animij_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false
    },
    {
      "name": "AniSora v2 I2V Wan 2.1 14B",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v2_i2v_wan_2.1_14b_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[AniSora v2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation."
    },
    {
      "name": "AniSora v2 I2V Wan 2.1 14B (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v2_i2v_wan_2.1_14b_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[AniSora v2](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "builtin_lora": true
    },
    {
      "name": "AniSora v3.1 I2V Wan 2.1 14B",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v3.1_i2v_wan_2.1_14b_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[AniSora v3.1](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation."
    },
    {
      "name": "AniSora v3.1 I2V Wan 2.1 14B (6-bit, SVDQuant)",
      "version": "wan_v2.1_14b",
      "modifier": "inpainting",
      "autoencoder": "wan_v2.1_video_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 12,
      "hires_fix_scale": 16,
      "file": "anisora_v3.1_i2v_wan_2.1_14b_q6p_svd.ckpt",
      "upcast_attention": false,
      "text_encoder": "umt5_xxl_encoder_q8p.ckpt",
      "clip_encoder": "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
      "high_precision_autoencoder": false,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "frames_per_second": 16,
      "tea_cache_coefficients": [
        8107.0546,
        2133.93892,
        -372.934672,
        16.6203073,
        -0.0417769401
      ],
      "note": "[AniSora v3.1](https://huggingface.co/IndexTeam/Index-anisora) is a state-of-the-art image-to-video model fine-tuned by Bilibili for anime generation.",
      "builtin_lora": true
    },
    {
      "text_encoder": "artofura_furry_mix_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "file": "artofura_furry_mix_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "artofura_furry_mix_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "name": "Artofura-Furry-mix",
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "upcast_attention": false
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "974825_artsydream_v1fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v1FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "974932_artsydream_v1fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v1FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1004320_artsydream_v2fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v2FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1004235_artsydream_v2fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v2FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1023964_artsydream_v3fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v3FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1023471_artsydream_v3fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v3FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1071391_artsydream_v4fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v4FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1070930_artsydream_v4fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v4FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1136806_artsydream_v5fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v5FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1136364_artsydream_v5fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v5FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1213649_artsydream_v6fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v6FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1213097_artsydream_v6fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Dream_v6FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1308807_artsyvibe_v1fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Vibe_v1FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1308180_artsyvibe_v1fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Vibe_v1FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1842885_artsyvibe_v2fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Vibe_v2FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1840540_artsyvibe_v2fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Artsy_Vibe_v2FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "asian_realism_by_stable_yogi_pony_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "text_encoder": "asian_realism_by_stable_yogi_pony_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "asian_realism_by_stable_yogi_pony_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "name": "Asian-Realism-By-Stable-Yogi-PONY",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "980131_atomixfluxunet_v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Atomix_FLUXUnet_v10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "aungir_aungir_t6a4_1405004_f16.ckpt",
      "prefix": "",
      "name": "Aungir_Aungir_T6A4_1405004",
      "modifier": "none",
      "clip_encoder": "aungir_aungir_t6a4_1405004_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "text_encoder": "aungir_aungir_t6a4_1405004_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "prefix": "",
      "file": "aungir_aungir_t6ao4.5_1723632_f16.ckpt",
      "clip_encoder": "aungir_aungir_t6ao4.5_1723632_clip_vit_l14_f16.ckpt",
      "text_encoder": "aungir_aungir_t6ao4.5_1723632_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Aungir_Aungir_T6AO4.5_1723632",
      "modifier": "none",
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "text_encoder": "big_love_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "name": "Big-Love",
      "clip_encoder": "big_love_clip_vit_l14_f16.ckpt",
      "file": "big_love_f16.ckpt"
    },
    {
      "name": "Bismuth-Illustrious-Mix",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "clip_encoder": "bismuth_illustrious_mix_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "file": "bismuth_illustrious_mix_f16.ckpt",
      "text_encoder": "bismuth_illustrious_mix_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "modifier": "none"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "clip_encoder": "blendermix_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "file": "blendermix_f16.ckpt",
      "modifier": "none",
      "text_encoder": "blendermix_open_clip_vit_bigg14_f16.ckpt",
      "name": "BlenderMix",
      "upcast_attention": false
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "808159_bluepencilflux1_v010_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Blue_Pencil_Flux1_v010",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "867256_bluepencilflux1_v021_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Blue_Pencil_Flux1_v021",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "default_scale": 16,
      "prefix": "",
      "name": "boleromixillustrious",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "boleromixillustrious_clip_vit_l14_f16.ckpt",
      "text_encoder": "boleromixillustrious_open_clip_vit_bigg14_f16.ckpt",
      "file": "boleromixillustrious_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "978066_c4pacitor_av2alpha_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_a_V2Alpha",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1035832_c4pacitor_av2beta_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_a_V2Beta",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "845592_c4pacitor_dv1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_d_V1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "949363_c4pacitor_dv11_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_d_V11",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1123235_c4pacitor_dv2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_d_V2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1700674_c4pacitor_dv3alpha_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_d_V3Alpha",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "954181_c4pacitor_sv11_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_s_V11",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1086868_c4pacitor_sv2alpha_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "C4pacitor_s_V2Alpha",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "modifier": "none",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "name": "Candied-Anime-IllustriousXL",
      "upcast_attention": false,
      "clip_encoder": "candied_anime_illustriousxl_clip_vit_l14_f16.ckpt",
      "file": "candied_anime_illustriousxl_f16.ckpt",
      "text_encoder": "candied_anime_illustriousxl_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1178183_centerfoldflux_v35fp8e54steps_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Centerfold_Flux_v35FP8E54Steps",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1845222_centerfoldflux_v40fp8e5m2_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Centerfold_Flux_v40Fp8E5m2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "name": "Chroma v38 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v38_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v38 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v38_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v39 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v39_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v39 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v39_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v40 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v40_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v40 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v40_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v41 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v41_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v41 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v41_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v42 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v42_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v42 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v42_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v43 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v43_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v43 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v43_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v44 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v44_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v44 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v44_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v45 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v45_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v45 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v45_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v46 Detail Calibrated",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v46_detail_calibrated_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma v46 Detail Calibrated (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_v46_detail_calibrated_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma](https://huggingface.co/lodestones/Chroma)."
    },
    {
      "name": "Chroma1 HD Annealed",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_1_hd_annealed_q8p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma1 HD](https://huggingface.co/lodestones/Chroma1-HD)."
    },
    {
      "name": "Chroma1 HD Annealed (5-bit)",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "file": "chroma_1_hd_annealed_q5p.ckpt",
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "padded_text_encoding_length": 256,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "mmdit": {
        "dual_attention_layers": [],
        "distilled_guidance_layers": 5,
        "qk_norm": true
      },
      "note": "See more about [Chroma1 HD](https://huggingface.co/lodestones/Chroma1-HD)."
    },
    {
      "default_scale": 16,
      "prefix": "",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "file": "circusmix_f16.ckpt",
      "text_encoder": "circusmix_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "circusmix_clip_vit_l14_f16.ckpt",
      "name": "CircusMix",
      "modifier": "none"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "765642_colorfulasiangirlflux_beta_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colorfulasiangirl_Flux_beta",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "996001_colossusprojectflux_21dedistilledaioexp_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_21De_Distilled_AIOExp",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1846322_colossusprojectflux_v10aiofp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10AIOFP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "931988_colossusprojectflux_v10allinonefp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10All_In_One_Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1860608_colossusprojectflux_v10bfp8aiobobfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10b_FP8AIOBOBFP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1851709_colossusprojectflux_v10behemothaiofp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10Behemoth_AIOFP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "940696_colossusprojectflux_v10fp16unetonly_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10FP16UNETONLY",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1855312_colossusprojectflux_v10unetonlyfp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10UNETOnly_FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1848909_colossusprojectflux_v10unetonlyfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v10UNETOnly_FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "971579_colossusprojectflux_v20allinoneexp_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v20All_In_One_Exp",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1159932_colossusprojectflux_v42aio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v42AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1495910_colossusprojectflux_v44aio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v44AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1443922_colossusprojectflux_v50aio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v50AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1507835_colossusprojectflux_v50aiobehemoth_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v50AIOBehemoth",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1462430_colossusprojectflux_v50fp8unet_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v50FP8UNET",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1703060_colossusprojectflux_v90aio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Colossus_Project_Flux_v90AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1045901_copaxtimeless_fluxrealfast_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_fluxreal_Fast",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "894590_copaxtimeless_stylemix1fluxdevfp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_stylemix1Flux_Dev_FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "897535_copaxtimeless_stylemix1fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_stylemix1Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "975743_copaxtimeless_stylemix2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_stylemix2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1338565_copaxtimeless_xpluscartoon_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_Cartoon",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "954640_copaxtimeless_xplusmix1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_MIX1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "962412_copaxtimeless_xplusmix1fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_MIX1FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "982160_copaxtimeless_xplusmix2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_MIX2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1134093_copaxtimeless_xplusmix3_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_MIX3",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1148473_copaxtimeless_xplusmix3dark_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_MIX3Dark",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1217501_copaxtimeless_xplusmix4_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_MIX4",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "801556_copaxtimeless_xplusposes_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_Poses",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "783956_copaxtimeless_xplusunrealfast_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus_Unreal_Fast",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "778112_copaxtimeless_xplus1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "907183_copaxtimeless_xplus2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1085190_copaxtimeless_xplus2basetrain_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Copax_Timeless_xplus2Base_Train",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "copax_pony_xl_f16.ckpt",
      "name": "Copax-Pony-XL",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "copax_pony_xl_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "prefix": "",
      "upcast_attention": false,
      "text_encoder": "copax_pony_xl_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "text_encoder": "crow___pony_qp_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "crow___pony_qp_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "name": "Crow-Pony-qp",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "file": "crow___pony_qp_f16.ckpt"
    },
    {
      "prefix": "",
      "text_encoder": "cyberillustrious_cyberrealistic_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "clip_encoder": "cyberillustrious_cyberrealistic_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "name": "CyberIllustrious-CyberRealistic",
      "file": "cyberillustrious_cyberrealistic_f16.ckpt",
      "default_scale": 16
    },
    {
      "default_scale": 8,
      "upcast_attention": false,
      "prefix": "",
      "name": "CyberRealistic",
      "text_encoder": "cyberrealistic_clip_vit_l14_f16.ckpt",
      "version": "v1",
      "file": "cyberrealistic_f16.ckpt",
      "modifier": "none"
    },
    {
      "name": "CyberRealistic Flux v2.5",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ],
      "file": "cyberrealistic_flux_v2.5_f16.ckpt",
      "modifier": "none"
    },
    {
      "name": "CyberRealistic Flux v2.5",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ],
      "file": "cyberrealistic_flux_v2.5_q8p.ckpt",
      "modifier": "none"
    },
    {
      "name": "CyberRealistic_Pony_v8_1346181",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "cyberrealistic_pony_v8_1346181_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "file": "cyberrealistic_pony_v8_1346181_f16.ckpt",
      "prefix": "",
      "clip_encoder": "cyberrealistic_pony_v8_1346181_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16
    },
    {
      "file": "cyberrealistic_pony_v8.5_1478064_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "text_encoder": "cyberrealistic_pony_v8.5_1478064_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "clip_encoder": "cyberrealistic_pony_v8.5_1478064_clip_vit_l14_f16.ckpt",
      "name": "CyberRealistic_Pony_v8.5_1478064"
    },
    {
      "prefix": "",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "text_encoder": "cyberrealistic_pony_v9.0_alt_1_1691220_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "cyberrealistic_pony_v9.0_alt_1_1691220_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "name": "CyberRealistic_Pony_v9.0_Alt_1_1691220",
      "file": "cyberrealistic_pony_v9.0_alt_1_1691220_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "name": "CyberRealistic-Pony-Catalyst",
      "file": "cyberrealistic_pony_catalyst_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "cyberrealistic_pony_catalyst_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "clip_encoder": "cyberrealistic_pony_catalyst_clip_vit_l14_f16.ckpt",
      "prefix": ""
    },
    {
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "text_encoder": "cyberrealistic_pony_semi_realistic_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "cyberrealistic_pony_semi_realistic_clip_vit_l14_f16.ckpt",
      "name": "CyberRealistic-Pony-Semi-Realistic",
      "file": "cyberrealistic_pony_semi_realistic_f16.ckpt",
      "default_scale": 16,
      "upcast_attention": false
    },
    {
      "file": "cyberrealistic_xl_f16.ckpt",
      "name": "CyberRealistic-XL",
      "upcast_attention": false,
      "text_encoder": "cyberrealistic_xl_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "cyberrealistic_xl_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1048219_demoncoresfwnsfw_fluxv13_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Demon_CORESFWNSFW_flux_V13",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1357212_demoncoresfwnsfw_v25helheimprojectaio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Demon_CORESFWNSFW_v25Helheim_Project_AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "prefix": "",
      "name": "DHXL-v1.0",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "default_scale": 16,
      "text_encoder": "dhxl_v1.0_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "dhxl_v1.0_clip_vit_l14_f16.ckpt",
      "file": "dhxl_v1.0_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "prefix": "",
      "text_encoder": "dixar_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "dixar_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "name": "Dixar",
      "modifier": "none",
      "file": "dixar_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "modifier": "none",
      "file": "dreamisoa_remix_f16.ckpt",
      "name": "Dreamisoa-remix",
      "default_scale": 16,
      "text_encoder": "dreamisoa_remix_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "dreamisoa_remix_clip_vit_l14_f16.ckpt"
    },
    {
      "name": "DucHaiten_Pony_XL_no_score_v5.2_706363",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "file": "duchaiten_pony_xl_no_score_v5.2_706363_f16.ckpt",
      "clip_encoder": "duchaiten_pony_xl_no_score_v5.2_706363_clip_vit_l14_f16.ckpt",
      "text_encoder": "duchaiten_pony_xl_no_score_v5.2_706363_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "text_encoder": "duchaiten_pony_xl_no_score_v6.0_817261_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "clip_encoder": "duchaiten_pony_xl_no_score_v6.0_817261_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "duchaiten_pony_xl_no_score_v6.0_817261_f16.ckpt",
      "name": "DucHaiten_Pony_XL_no_score_v6.0_817261",
      "version": "sdxl_base_v0.9"
    },
    {
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "file": "duchaiten_cool_age_f16.ckpt",
      "prefix": "",
      "clip_encoder": "duchaiten_cool_age_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "duchaiten_cool_age_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "name": "DucHaiten-Cool-Age"
    },
    {
      "upcast_attention": false,
      "prefix": "",
      "modifier": "none",
      "file": "duchaiten_noobai_f16.ckpt",
      "name": "DucHaiten-NoobAI",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "duchaiten_noobai_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "duchaiten_noobai_clip_vit_l14_f16.ckpt"
    },
    {
      "prefix": "",
      "modifier": "none",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "file": "duchaiten_noobai_cinematic_f16.ckpt",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "name": "DucHaiten-NoobAI-Cinematic",
      "clip_encoder": "duchaiten_noobai_cinematic_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "text_encoder": "duchaiten_noobai_cinematic_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "file": "duchaiten_pony_real_f16.ckpt",
      "text_encoder": "duchaiten_pony_real_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "name": "DucHaiten-Pony-Real",
      "prefix": "",
      "modifier": "none",
      "clip_encoder": "duchaiten_pony_real_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1677057_edgeofreality_32beyondreality_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Edge_Of_Reality_32Beyond_Reality",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1224657_edgeofreality_v30_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Edge_Of_Reality_v30",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "editijon_k_pop_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "editijon_k_pop_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "editijon_k_pop_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "name": "Editijon-K-POP",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none"
    },
    {
      "prefix": "",
      "text_encoder": "epicrealism_xl_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "epicrealism_xl_clip_vit_l14_f16.ckpt",
      "file": "epicrealism_xl_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "epiCRealism-XL",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "default_scale": 16,
      "modifier": "none"
    },
    {
      "name": "Eri-LumenVeil-V1-Illustrious-NAI",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "eri_lumenveil_v1_illustrious_nai_clip_vit_l14_f16.ckpt",
      "text_encoder": "eri_lumenveil_v1_illustrious_nai_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "upcast_attention": false,
      "file": "eri_lumenveil_v1_illustrious_nai_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none"
    },
    {
      "name": "Fantasm-Pony-XL",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "fantasm_pony_xl_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "file": "fantasm_pony_xl_f16.ckpt",
      "prefix": "",
      "text_encoder": "fantasm_pony_xl_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "795206_fenrisxlflux_fenrisfluxv1fp8_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fenrisxl_Flux_fenris_Flux_V1FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "modifier": "none",
      "clip_encoder": "five_stars_illustrious_1.0_1398525_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "five_stars_illustrious_1.0_1398525_f16.ckpt",
      "name": "Five_Stars_Illustrious_1.0_1398525",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "text_encoder": "five_stars_illustrious_1.0_1398525_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "file": "five_stars_illustrious_4.0_1657020_f16.ckpt",
      "upcast_attention": false,
      "name": "Five_Stars_Illustrious_4.0_1657020",
      "default_scale": 16,
      "prefix": "",
      "clip_encoder": "five_stars_illustrious_4.0_1657020_clip_vit_l14_f16.ckpt",
      "text_encoder": "five_stars_illustrious_4.0_1657020_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "959302_fluxrealistic_fluxrealisticsamayv2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux_Realistic_flux_Realistic_Samay_V2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1054490_flux1_v10fp8_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1_v10Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1103485_flux1_v10fp8schnell_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1_v10Fp8Schnell",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1219311_flux1_v20fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1_v20Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1319871_flux1_v30fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1_v30Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1442202_flux1_v30papfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1_v30PAPFp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "752959_flux1devasian_v10fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1Dev_Asian_v10FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1519790_flux1eastfp8_canny_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "depth",
      "name": "Flux1east_Fp8_canny",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1519801_flux1eastfp8_depth_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "depth",
      "name": "Flux1east_Fp8_depth",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1519030_flux1eastfp8_dev_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Flux1east_Fp8_dev",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1519446_flux1eastfp8_fill_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "inpainting",
      "name": "Flux1east_Fp8_fill",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "947686_fluxedupfluxnsfw_10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1126942_fluxedupfluxnsfw_21_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_21",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1182699_fluxedupfluxnsfw_22_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_22",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1305680_fluxedupfluxnsfw_24_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_24",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1466679_fluxedupfluxnsfw_25_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_25",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1700814_fluxedupfluxnsfw_40devfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_40Dev_Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1823302_fluxedupfluxnsfw_41_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxed_Up_Flux_NSFW_41",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1050076_fluxmania_i_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxmania_i",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1463804_fluxmania_iv_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxmania_iv",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1769925_fluxmania_legacy_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxmania_legacy",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1539776_fluxmania_v_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Fluxmania_v",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "upcast_attention": false,
      "default_scale": 16,
      "file": "furrytoonmix_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "furrytoonmix_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "name": "FurryToonMix",
      "text_encoder": "furrytoonmix_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1329004_genovaapex_1618experiment_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Genova_APEX_1618Experiment",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1831456_genovaapex_genovav2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Genova_APEX_genova_V2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1209969_genovaapex_plus_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Genova_APEX_plus",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1111281_genovaapex_real_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Genova_APEX_real",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1068773_genovaapex_s_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Genova_APEX_s",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "name": "getphat FLUX Reality NSFW v11 Softcore",
      "version": "flux1",
      "autoencoder": "flux_1_vae_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "hires_fix_scale": 24,
      "upcast_attention": false,
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "high_precision_autoencoder": true,
      "guidance_embed": true,
      "padded_text_encoding_length": 512,
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "tea_cache_coefficients": [
        498.651651,
        -283.781631,
        55.8554382,
        -3.82021401,
        0.264230861
      ],
      "modifier": "none",
      "file": "getphat_flux_reality_nsfw_v11_softcore_q8p.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1868950_gonzalomoxlfluxpony_v03fluxityfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Gonzalomo_XLFlux_Pony_v03Fluxity_Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1883195_gonzalomoxlfluxpony_v10fluxityfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Gonzalomo_XLFlux_Pony_v10Fluxity_Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "homosimile_xl_pony__illustrious__noobai_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "text_encoder": "homosimile_xl_pony__illustrious__noobai_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "clip_encoder": "homosimile_xl_pony__illustrious__noobai_clip_vit_l14_f16.ckpt",
      "name": "HomoSimile-XL-Pony_-Illustrious_-NoobAI"
    },
    {
      "default_scale": 16,
      "upcast_attention": false,
      "file": "hoseki_lustrousmix_illustriousxl_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "hoseki_lustrousmix_illustriousxl_clip_vit_l14_f16.ckpt",
      "name": "Hoseki-LustrousMix-IllustriousXL",
      "prefix": "",
      "text_encoder": "hoseki_lustrousmix_illustriousxl_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "hoseki_lustrousmix_pony_xl_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "clip_encoder": "hoseki_lustrousmix_pony_xl_clip_vit_l14_f16.ckpt",
      "text_encoder": "hoseki_lustrousmix_pony_xl_open_clip_vit_bigg14_f16.ckpt",
      "name": "Hoseki-LustrousMix-Pony-XL",
      "default_scale": 16,
      "prefix": ""
    },
    {
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "clip_encoder": "hs_ultrahd_cg_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "name": "Hs-UltraHD-CG",
      "upcast_attention": false,
      "file": "hs_ultrahd_cg_f16.ckpt",
      "modifier": "none",
      "text_encoder": "hs_ultrahd_cg_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1254943_hyperfluxdedistilled_hyper16stepsfp8_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Hyper_Flux_Dedistilled_hyper16Steps_FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1255083_hyperfluxdedistilled_hyper8stepsfp8_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Hyper_Flux_Dedistilled_hyper8Steps_FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "name": "IcedCoffeeIL",
      "default_scale": 16,
      "text_encoder": "icedcoffeeil_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "icedcoffeeil_clip_vit_l14_f16.ckpt",
      "file": "icedcoffeeil_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "prefix": "",
      "default_scale": 16,
      "clip_encoder": "iffymix_xl_clip_vit_l14_f16.ckpt",
      "file": "iffymix_xl_f16.ckpt",
      "name": "IffyMix-XL",
      "text_encoder": "iffymix_xl_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "illumiyume_xl_illustrious_f16.ckpt",
      "clip_encoder": "illumiyume_xl_illustrious_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "upcast_attention": false,
      "text_encoder": "illumiyume_xl_illustrious_open_clip_vit_bigg14_f16.ckpt",
      "name": "IllumiYume-XL-Illustrious"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1108227_illustrationjuanerghibli_v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Illustration_Juaner_Ghibli_v10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1215918_illustrationjuanerghibli_v20_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Illustration_Juaner_Ghibli_v20",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "version": "sdxl_base_v0.9",
      "file": "illustrij_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "modifier": "none",
      "text_encoder": "illustrij_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "illustrij_clip_vit_l14_f16.ckpt",
      "name": "Illustrij",
      "prefix": ""
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Illustrij-GENv1",
      "modifier": "none",
      "file": "illustrij_genv1_f16.ckpt",
      "clip_encoder": "illustrij_genv1_clip_vit_l14_f16.ckpt",
      "text_encoder": "illustrij_genv1_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Illustrij-GENv1 (8-bit)",
      "modifier": "none",
      "file": "illustrij_genv1_q6p_q8p.ckpt",
      "clip_encoder": "illustrij_genv1_clip_vit_l14_f16.ckpt",
      "text_encoder": "illustrij_genv1_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "prefix": "",
      "name": "Illustrious-Black-Magic-Illustrious-Noob-More",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "file": "illustrious_black_magic_illustrious_noob_more_f16.ckpt",
      "clip_encoder": "illustrious_black_magic_illustrious_noob_more_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "modifier": "none",
      "text_encoder": "illustrious_black_magic_illustrious_noob_more_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "illustrious_gehenna_illustrious_checkpoint_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "prefix": "",
      "name": "Illustrious-Gehenna-Illustrious-Checkpoint",
      "text_encoder": "illustrious_gehenna_illustrious_checkpoint_open_clip_vit_bigg14_f16.ckpt",
      "file": "illustrious_gehenna_illustrious_checkpoint_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "name": "Illustrious-Realism-by-klaabu",
      "modifier": "none",
      "clip_encoder": "illustrious_realism_by_klaabu_clip_vit_l14_f16.ckpt",
      "file": "illustrious_realism_by_klaabu_f16.ckpt",
      "text_encoder": "illustrious_realism_by_klaabu_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "prefix": "",
      "modifier": "none",
      "name": "Illustrious-XL",
      "clip_encoder": "illustrious_xl_clip_vit_l14_f16.ckpt",
      "text_encoder": "illustrious_xl_open_clip_vit_bigg14_f16.ckpt",
      "file": "illustrious_xl_f16.ckpt",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16
    },
    {
      "prefix": "",
      "name": "Illustrious-XL-personal-merge-noob-v-pred0.5-test-merge-updated",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "illustrious_xl_personal_merge_noob_v_pred0.5_test_merge_updated_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "modifier": "none",
      "upcast_attention": false,
      "file": "illustrious_xl_personal_merge_noob_v_pred0.5_test_merge_updated_f16.ckpt",
      "clip_encoder": "illustrious_xl_personal_merge_noob_v_pred0.5_test_merge_updated_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Inbetweij — No.04",
      "modifier": "none",
      "clip_encoder": "inbetweij___no.04_clip_vit_l14_f16.ckpt",
      "file": "inbetweij___no.04_f16.ckpt",
      "text_encoder": "inbetweij___no.04_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Inbetweij — No.04 (8-bit)",
      "modifier": "none",
      "clip_encoder": "inbetweij___no.04_clip_vit_l14_f16.ckpt",
      "file": "inbetweij___no.04_q6p_q8p.ckpt",
      "text_encoder": "inbetweij___no.04_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "prefix": "",
      "text_encoder": "indigo_void_furry_fused_xl_furry_noobai_noobai_v1.7_1569147_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "indigo_void_furry_fused_xl_furry_noobai_noobai_v1.7_1569147_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "file": "indigo_void_furry_fused_xl_furry_noobai_noobai_v1.7_1569147_f16.ckpt",
      "name": "Indigo_Void_Furry_Fused_XL_Furry_NoobAI_NoobAI_v1.7_1569147",
      "upcast_attention": false,
      "default_scale": 16,
      "version": "sdxl_base_v0.9"
    },
    {
      "text_encoder": "indigo_void_furry_fused_xl_furry_noobai_noobai_v1.8_1731573_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false,
      "name": "Indigo_Void_Furry_Fused_XL_Furry_NoobAI_NoobAI_v1.8_1731573",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "file": "indigo_void_furry_fused_xl_furry_noobai_noobai_v1.8_1731573_f16.ckpt",
      "clip_encoder": "indigo_void_furry_fused_xl_furry_noobai_noobai_v1.8_1731573_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9"
    },
    {
      "file": "indigo_furry_mix_xl_f16.ckpt",
      "modifier": "none",
      "text_encoder": "indigo_furry_mix_xl_open_clip_vit_bigg14_f16.ckpt",
      "name": "Indigo-Furry-Mix-XL",
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "clip_encoder": "indigo_furry_mix_xl_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false
    },
    {
      "upcast_attention": false,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "file": "indigo_void_furry_vpred_furry_noobai_v_pred_f16.ckpt",
      "name": "Indigo-Void-Furry-Vpred-Furry-NoobAI-V-pred",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "indigo_void_furry_vpred_furry_noobai_v_pred_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "text_encoder": "indigo_void_furry_vpred_furry_noobai_v_pred_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1006775_iniversemixsfwnsfw_f1drealguofengfp8v20_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Iniverse_Mix_SFWNSFW_f1d_Real_Guofeng_Fp8V20",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1031531_iniversemixsfwnsfw_f1drealnsfwguofengv2_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Iniverse_Mix_SFWNSFW_f1d_Realnsfw_Guofeng_V2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "973626_iniversemixsfwnsfw_flux1dnsfwfp16v12_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Iniverse_Mix_SFWNSFW_flux1DNsfw_Fp16V12",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "966095_iniversemixsfwnsfw_flux1dnsfwfp8v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Iniverse_Mix_SFWNSFW_flux1DNsfw_Fp8V10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "ionsyx_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "name": "Ionsyx",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "clip_encoder": "ionsyx_clip_vit_l14_f16.ckpt",
      "text_encoder": "ionsyx_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "886474_isenganmixflux_vb_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Isenganmix_Flux_v_B",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "796103_jibmixflux_fp16v1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_fp16V1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "918242_jibmixflux_fp8v2electric_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_fp8V2Electric",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1001176_jibmixflux_fp8v4canvasgalore_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_fp8V4Canvas_Galore",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1249737_jibmixflux_v72pixelheaven_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_v72Pixel_Heaven",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1355240_jibmixflux_v78cleartextfocus_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_v78Clear_Text_Focus",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1193229_jibmixflux_v7pixelheavenbeta_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_v7Pixel_Heaven_Beta",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1755367_jibmixflux_v85consisteight_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_v85Consisteight",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1389019_jibmixflux_v8accentueightnow_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Jib_Mix_Flux_v8Accentueight_Now",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "clip_encoder": "jib_mix_pony_realistic_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Jib-Mix-Pony-Realistic",
      "modifier": "none",
      "file": "jib_mix_pony_realistic_f16.ckpt",
      "text_encoder": "jib_mix_pony_realistic_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "upcast_attention": false
    },
    {
      "name": "Jib-Mix-Realistic-XL",
      "clip_encoder": "jib_mix_realistic_xl_clip_vit_l14_f16.ckpt",
      "text_encoder": "jib_mix_realistic_xl_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "file": "jib_mix_realistic_xl_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "prefix": ""
    },
    {
      "file": "jujumix_f16.ckpt",
      "text_encoder": "jujumix_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "jujumix_clip_vit_l14_f16.ckpt",
      "name": "JujuMix",
      "prefix": "",
      "default_scale": 16,
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Kageillustrious-Illustrious-XL",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "text_encoder": "kageillustrious_illustrious_xl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "kageillustrious_illustrious_xl_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "kageillustrious_illustrious_xl_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "text_encoder": "kantanmix_xlillustrious_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "file": "kantanmix_xlillustrious_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "clip_encoder": "kantanmix_xlillustrious_clip_vit_l14_f16.ckpt",
      "name": "KantanMIX-XLIllustrious",
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "KFT-Requiem-Fur-a-Dream-Illustrious-Semi-Real-Checkpoint",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "file": "kft_requiem_fur_a_dream_illustrious_semi_real_checkpoint_f16.ckpt",
      "text_encoder": "kft_requiem_fur_a_dream_illustrious_semi_real_checkpoint_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "clip_encoder": "kft_requiem_fur_a_dream_illustrious_semi_real_checkpoint_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "KonanMix-NoobAI-XL-IllustriousXL",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "konanmix_noobai_xl_illustriousxl_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "text_encoder": "konanmix_noobai_xl_illustriousxl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "file": "konanmix_noobai_xl_illustriousxl_f16.ckpt",
      "upcast_attention": false,
      "prefix": ""
    },
    {
      "modifier": "none",
      "clip_encoder": "koronemix_illustrious_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "file": "koronemix_illustrious_f16.ckpt",
      "prefix": "",
      "name": "koronemix-illustrious",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "text_encoder": "koronemix_illustrious_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "872820_lahmysteriousflux_fluxalpha_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Lah_Mysterious_Flux_flux_Alpha",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "default_scale": 16,
      "upcast_attention": false,
      "prefix": "",
      "modifier": "none",
      "clip_encoder": "like_reality_pony_by_ethanar_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "text_encoder": "like_reality_pony_by_ethanar_open_clip_vit_bigg14_f16.ckpt",
      "name": "Like-Reality-Pony-by-Ethanar",
      "file": "like_reality_pony_by_ethanar_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Lox_s-Souls-Mix-Prisma-",
      "version": "sdxl_base_v0.9",
      "text_encoder": "lox_s_souls_mix_prisma__open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "lox_s_souls_mix_prisma__clip_vit_l14_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "modifier": "none",
      "file": "lox_s_souls_mix_prisma__f16.ckpt",
      "upcast_attention": false
    },
    {
      "clip_encoder": "lunargrapemix_illustrious_clip_vit_l14_f16.ckpt",
      "file": "lunargrapemix_illustrious_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "text_encoder": "lunargrapemix_illustrious_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "LunarGrapeMix-Illustrious",
      "prefix": "",
      "upcast_attention": false
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "835744_lyhanimeflux_delete_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Lyh_Anime_Flux_delete",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "clip_encoder": "madly_mix_ver_nightnoob_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "modifier": "none",
      "prefix": "",
      "text_encoder": "madly_mix_ver_nightnoob_open_clip_vit_bigg14_f16.ckpt",
      "file": "madly_mix_ver_nightnoob_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Madly-Mix-ver-NightNoob"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1247362_majicflus_v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Majicflus_v10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "meichidarkmix_reload_f16.ckpt",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "text_encoder": "meichidarkmix_reload_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "name": "MeichiDarkMix-Reload",
      "default_scale": 16,
      "prefix": "",
      "clip_encoder": "meichidarkmix_reload_clip_vit_l14_f16.ckpt"
    },
    {
      "name": "miruku",
      "prefix": "",
      "clip_encoder": "miruku_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "miruku_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "file": "miruku_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "mistoon_anime_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "text_encoder": "mistoon_anime_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "file": "mistoon_anime_f16.ckpt",
      "name": "Mistoon-Anime",
      "modifier": "none",
      "upcast_attention": false
    },
    {
      "upcast_attention": false,
      "default_scale": 16,
      "modifier": "none",
      "file": "mol_keun_mix_f16.ckpt",
      "name": "Mol-Keun-Mix",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "clip_encoder": "mol_keun_mix_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "text_encoder": "mol_keun_mix_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "prefix": "",
      "file": "molcajetemix_noobil_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "MolcajeteMix-NoobIL",
      "upcast_attention": false,
      "text_encoder": "molcajetemix_noobil_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "molcajetemix_noobil_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "modifier": "none"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "905329_moxieflux1ds_flux1d8step_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Flux1DS_flux1D8Step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "905879_moxieflux1ds_flux1s8step_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Flux1DS_flux1S8Step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "883958_moxieflux1ds_v138step_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Flux1DS_v138Step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "986682_moxieflux1ds_v14_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Flux1DS_v14",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1453489_moxieflux1ds_v16d_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Flux1DS_v16D",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1802008_moxieflux1ds_v17s_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Flux1DS_v17S",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1718411_moxiefusionflux_17d_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_17D",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "876813_moxiefusionflux_v1318step_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v1318step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "874291_moxiefusionflux_v132_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v132",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "873546_moxiefusionflux_v1328step_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v1328step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "913024_moxiefusionflux_v1338step_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v1338step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "943051_moxiefusionflux_v134_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v134",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "932231_moxiefusionflux_v1348step_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v1348step",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "985269_moxiefusionflux_v135_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v135",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1255371_moxiefusionflux_v141d_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v141D",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1249359_moxiefusionflux_v141s_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v141S",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1292596_moxiefusionflux_v15s_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v15S",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1473409_moxiefusionflux_v16s_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v16S",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1742386_moxiefusionflux_v17s_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Moxie_Fusion_Flux_v17S",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1505959_msfluxsfwnsfwv3_v3_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ms_Flux_SFWNSFWV3_v3",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "866874_myhumanflux_12train_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Myhuman_Flux_12Train",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "885693_myhumanflux_myh11_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Myhuman_Flux_myh11",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "989443_myhumanflux_myh13_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Myhuman_Flux_myh13",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "991687_myhumanflux_myh13fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Myhuman_Flux_myh13Fp8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1288366_nepotism_xdit_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Nepotism_x_Dit",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1326315_nepotism_xidit_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Nepotism_xi_Dit",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "text_encoder": "nevolution_sdxl_v2_anim_1733673_open_clip_vit_bigg14_f16.ckpt",
      "file": "nevolution_sdxl_v2_anim_1733673_f16.ckpt",
      "name": "Nevolution_SDXL_v2_anim_1733673",
      "default_scale": 16,
      "modifier": "none",
      "prefix": "",
      "upcast_attention": false,
      "clip_encoder": "nevolution_sdxl_v2_anim_1733673_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "prefix": "",
      "text_encoder": "nevolution_sdxl_v2_base_1645671_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Nevolution_SDXL_v2_base_1645671",
      "file": "nevolution_sdxl_v2_base_1645671_f16.ckpt",
      "default_scale": 16,
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "nevolution_sdxl_v2_base_1645671_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "default_scale": 16,
      "text_encoder": "noobai_xl_nai_xl_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "noobai_xl_nai_xl_clip_vit_l14_f16.ckpt",
      "name": "NoobAI-XL-NAI-XL",
      "modifier": "none",
      "upcast_attention": false,
      "file": "noobai_xl_nai_xl_f16.ckpt"
    },
    {
      "modifier": "none",
      "name": "NostraMix",
      "clip_encoder": "nostramix_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "text_encoder": "nostramix_open_clip_vit_bigg14_f16.ckpt",
      "file": "nostramix_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "upcast_attention": false,
      "text_encoder": "nova_animal_xl_illustrious_v3.0_1634769_open_clip_vit_bigg14_f16.ckpt",
      "name": "Nova_Animal_XL_Illustrious_v3.0_1634769",
      "clip_encoder": "nova_animal_xl_illustrious_v3.0_1634769_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "file": "nova_animal_xl_illustrious_v3.0_1634769_f16.ckpt",
      "prefix": ""
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "name": "Nova_Animal_XL_v4.0_1028888",
      "default_scale": 16,
      "prefix": "",
      "text_encoder": "nova_animal_xl_v4.0_1028888_open_clip_vit_bigg14_f16.ckpt",
      "file": "nova_animal_xl_v4.0_1028888_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "nova_animal_xl_v4.0_1028888_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "text_encoder": "nova_furry_xl_illustrious_v6a_1625975_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "nova_furry_xl_illustrious_v6a_1625975_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "name": "Nova_Furry_XL_Illustrious_v6A_1625975",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "file": "nova_furry_xl_illustrious_v6a_1625975_f16.ckpt"
    },
    {
      "modifier": "none",
      "clip_encoder": "nova_furry_xl_illustrious_v6b_1626156_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "name": "Nova_Furry_XL_Illustrious_v6B_1626156",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "file": "nova_furry_xl_illustrious_v6b_1626156_f16.ckpt",
      "text_encoder": "nova_furry_xl_illustrious_v6b_1626156_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false
    },
    {
      "file": "nova_furry_xl_illustrious_v7a_1759909_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "nova_furry_xl_illustrious_v7a_1759909_open_clip_vit_bigg14_f16.ckpt",
      "name": "Nova_Furry_XL_Illustrious_v7A_1759909",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "nova_furry_xl_illustrious_v7a_1759909_clip_vit_l14_f16.ckpt",
      "default_scale": 16
    },
    {
      "clip_encoder": "nova_furry_xl_illustrious_v7b_1760102_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "modifier": "none",
      "file": "nova_furry_xl_illustrious_v7b_1760102_f16.ckpt",
      "name": "Nova_Furry_XL_Illustrious_v7B_1760102",
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "text_encoder": "nova_furry_xl_illustrious_v7b_1760102_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "modifier": "none",
      "file": "nova_orange_xl_v7.0_1525944_f16.ckpt",
      "clip_encoder": "nova_orange_xl_v7.0_1525944_clip_vit_l14_f16.ckpt",
      "name": "Nova_Orange_XL_v7.0_1525944",
      "default_scale": 16,
      "prefix": "",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "text_encoder": "nova_orange_xl_v7.0_1525944_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "text_encoder": "nova_orange_xl_v9.0_1701002_open_clip_vit_bigg14_f16.ckpt",
      "name": "Nova_Orange_XL_v9.0_1701002",
      "clip_encoder": "nova_orange_xl_v9.0_1701002_clip_vit_l14_f16.ckpt",
      "file": "nova_orange_xl_v9.0_1701002_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "default_scale": 16
    },
    {
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "name": "Nova-3DCG-XL",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "file": "nova_3dcg_xl_f16.ckpt",
      "text_encoder": "nova_3dcg_xl_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "clip_encoder": "nova_3dcg_xl_clip_vit_l14_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "clip_encoder": "nova_anime_xl_clip_vit_l14_f16.ckpt",
      "text_encoder": "nova_anime_xl_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "name": "Nova-Anime-XL",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "file": "nova_anime_xl_f16.ckpt"
    },
    {
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "nova_anime3d_xl_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "name": "Nova-Anime3D-XL",
      "file": "nova_anime3d_xl_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "text_encoder": "nova_anime3d_xl_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "file": "nova_asian_xl_f16.ckpt",
      "name": "Nova-Asian-XL",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "clip_encoder": "nova_asian_xl_clip_vit_l14_f16.ckpt",
      "text_encoder": "nova_asian_xl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": ""
    },
    {
      "default_scale": 16,
      "upcast_attention": false,
      "file": "nova_cross_xl_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "name": "Nova-Cross-XL",
      "text_encoder": "nova_cross_xl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "nova_cross_xl_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "prefix": "",
      "modifier": "none",
      "default_scale": 16,
      "file": "nova_flat_xl_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Nova-Flat-XL",
      "text_encoder": "nova_flat_xl_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "nova_flat_xl_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "file": "nova_reality_xl_f16.ckpt",
      "name": "Nova-Reality-XL",
      "upcast_attention": false,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "nova_reality_xl_clip_vit_l14_f16.ckpt",
      "text_encoder": "nova_reality_xl_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "prefix": "",
      "modifier": "none",
      "file": "nova_unreal_xl_f16.ckpt",
      "name": "Nova-Unreal-XL",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "text_encoder": "nova_unreal_xl_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "nova_unreal_xl_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "ONE-FOR-ALL-Pony-Fantasy-DPOVAE",
      "upcast_attention": false,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "text_encoder": "one_for_all_pony_fantasy_dpovae_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16,
      "modifier": "none",
      "file": "one_for_all_pony_fantasy_dpovae_f16.ckpt",
      "clip_encoder": "one_for_all_pony_fantasy_dpovae_clip_vit_l14_f16.ckpt"
    },
    {
      "modifier": "none",
      "file": "oops_all_toons_illustrious_v1.0_f16.ckpt",
      "name": "Oops-All-Toons-Illustrious-v1.0",
      "upcast_attention": false,
      "text_encoder": "oops_all_toons_illustrious_v1.0_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "clip_encoder": "oops_all_toons_illustrious_v1.0_clip_vit_l14_f16.ckpt"
    },
    {
      "prefix": "",
      "name": "Oops-All-vpred-NoobAI-Western-2D-furry-toon",
      "upcast_attention": false,
      "text_encoder": "oops_all_vpred_noobai_western_2d_furry_toon_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "oops_all_vpred_noobai_western_2d_furry_toon_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "file": "oops_all_vpred_noobai_western_2d_furry_toon_f16.ckpt",
      "modifier": "none",
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1308101_originbyn0utis_fluxfp8v1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Origin_By_N0utis_flux_FP8V1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "name": "Photonic-Fusion-SDXL",
      "file": "photonic_fusion_sdxl_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "text_encoder": "photonic_fusion_sdxl_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "upcast_attention": false,
      "modifier": "none",
      "clip_encoder": "photonic_fusion_sdxl_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Pikon_Realism_v2_alt",
      "modifier": "none",
      "file": "pikon_realism_v2_alt_f16.ckpt",
      "clip_encoder": "pikon_realism_v2_alt_clip_vit_l14_f16.ckpt",
      "text_encoder": "pikon_realism_v2_alt_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "name": "Pikon_Realism_v2_alt (8-bit)",
      "modifier": "none",
      "file": "pikon_realism_v2_alt_q6p_q8p.ckpt",
      "clip_encoder": "pikon_realism_v2_alt_clip_vit_l14_f16.ckpt",
      "text_encoder": "pikon_realism_v2_alt_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "826571_pixelwave_flux1dev02_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Pixelwave_flux1Dev02",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "992642_pixelwave_flux1dev03_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Pixelwave_flux1Dev03",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1002647_pixelwave_flux1schnell03_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Pixelwave_flux1Schnell03",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "plant_milk_model_suite_flax_1331188_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "text_encoder": "plant_milk_model_suite_flax_1331188_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "plant_milk_model_suite_flax_1331188_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "name": "Plant_Milk_Model_Suite_Flax_1331188",
      "version": "sdxl_base_v0.9"
    },
    {
      "file": "plant_milk_model_suite_hemp_ii_1714314_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "plant_milk_model_suite_hemp_ii_1714314_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false,
      "name": "Plant_Milk_Model_Suite_Hemp_II_1714314",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "modifier": "none",
      "clip_encoder": "plant_milk_model_suite_hemp_ii_1714314_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "clip_encoder": "pony_realism_v2.1_534642_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "name": "Pony_Realism_v2.1_534642",
      "file": "pony_realism_v2.1_534642_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "upcast_attention": false,
      "modifier": "none",
      "default_scale": 16,
      "text_encoder": "pony_realism_v2.1_534642_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Pony_Realism_v2.2_914390",
      "prefix": "",
      "default_scale": 16,
      "file": "pony_realism_v2.2_914390_f16.ckpt",
      "clip_encoder": "pony_realism_v2.2_914390_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "text_encoder": "pony_realism_v2.2_914390_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "file": "praeclarus_illustriousxl_f16.ckpt",
      "text_encoder": "praeclarus_illustriousxl_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Praeclarus-IllustriousXL",
      "modifier": "none",
      "prefix": "",
      "clip_encoder": "praeclarus_illustriousxl_clip_vit_l14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "text_encoder": "prefect_illustrious_xl_v1.0_1379960_open_clip_vit_bigg14_f16.ckpt",
      "file": "prefect_illustrious_xl_v1.0_1379960_f16.ckpt",
      "clip_encoder": "prefect_illustrious_xl_v1.0_1379960_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "name": "Prefect_illustrious_XL_v1.0_1379960",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "prefix": "",
      "modifier": "none",
      "version": "sdxl_base_v0.9"
    },
    {
      "modifier": "none",
      "name": "Prefect_illustrious_XL_v1.5_1731647",
      "text_encoder": "prefect_illustrious_xl_v1.5_1731647_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "prefect_illustrious_xl_v1.5_1731647_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "prefix": "",
      "default_scale": 16,
      "file": "prefect_illustrious_xl_v1.5_1731647_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "version": "sdxl_base_v0.9",
      "name": "Prefect-Pony-XL",
      "upcast_attention": false,
      "text_encoder": "prefect_pony_xl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "prefect_pony_xl_clip_vit_l14_f16.ckpt",
      "file": "prefect_pony_xl_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "806846_projectgaiaflux1d_v10unet_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project_Gaia_Flux1D_v10UNET",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1451754_project0_real1smfp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_real1sm_FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1591370_project0_real1smv2fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_real1sm_V2FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1596255_project0_real1smv2fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_real1sm_V2FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1875661_project0_real1smv3fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_real1sm_V3FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1878051_project0_real1smv3fp8aio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_real1sm_V3FP8AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1181877_project0_v10fp8unetonly_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_v10FP8Unet_Only",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1249092_project0_v20fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_v20FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1249496_project0_v20fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_v20FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1320268_project0_v30artfp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Project0_v30Art_FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "793143_ratatoskranimalcreature_v29_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ratatoskr_Animal_Creature_v29",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "835047_ratatoskranimalcreature_v40fp8_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ratatoskr_Animal_Creature_v40FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "873136_ratatoskranimalcreature_v41_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ratatoskr_Animal_Creature_v41",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1024165_ratatoskranimalcreature_v594fp8dev1hybrid_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ratatoskr_Animal_Creature_v594FP8Dev1Hybrid",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1637227_ratatoskranimalcreature_v667fp16_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ratatoskr_Animal_Creature_v667FP16",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1637484_ratatoskranimalcreature_v667fp8_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ratatoskr_Animal_Creature_v667FP8",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "ratatoskr_animal__creature_and_furry__f16.ckpt",
      "prefix": "",
      "modifier": "none",
      "upcast_attention": false,
      "clip_encoder": "ratatoskr_animal__creature_and_furry__clip_vit_l14_f16.ckpt",
      "name": "Ratatoskr-Animal_-Creature-and-Furry-",
      "text_encoder": "ratatoskr_animal__creature_and_furry__open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1186008_rayflux_v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Rayflux_v10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1785042_rayflux_v30aio_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Rayflux_v30AIO",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1703341_realdream_flux1v1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Real_Dream_flux1V1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "default_scale": 16,
      "clip_encoder": "realcartoon_xl_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "file": "realcartoon_xl_f16.ckpt",
      "name": "RealCartoon-XL",
      "prefix": "",
      "text_encoder": "realcartoon_xl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "881836_realflux10b_10bcompactschnell_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Realflux10b_10b_Compact_Schnell",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "882554_realflux10b_10btransformer_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Realflux10b_10b_Transformer",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "915279_realflux10b_10btransformerdev_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Realflux10b_10b_Transformer_Dev",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "clip_encoder": "realism_by_stable_yogi_pony_v3_vae_992946_clip_vit_l14_f16.ckpt",
      "name": "Realism_By_Stable_Yogi_Pony_V3_VAE_992946",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "file": "realism_by_stable_yogi_pony_v3_vae_992946_f16.ckpt",
      "prefix": "",
      "text_encoder": "realism_by_stable_yogi_pony_v3_vae_992946_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none"
    },
    {
      "name": "Realism_By_Stable_Yogi_v4.0_FP16_1422871",
      "prefix": "",
      "modifier": "none",
      "file": "realism_by_stable_yogi_v4.0_fp16_1422871_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "realism_by_stable_yogi_v4.0_fp16_1422871_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "text_encoder": "realism_by_stable_yogi_v4.0_fp16_1422871_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16
    },
    {
      "name": "Realism-SDXL-By-Stable-Yogi",
      "text_encoder": "realism_sdxl_by_stable_yogi_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "file": "realism_sdxl_by_stable_yogi_f16.ckpt",
      "default_scale": 16,
      "clip_encoder": "realism_sdxl_by_stable_yogi_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "clip_encoder": "realistic_blend_xl_clip_vit_l14_f16.ckpt",
      "file": "realistic_blend_xl_f16.ckpt",
      "upcast_attention": false,
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Realistic-Blend-XL",
      "modifier": "none",
      "text_encoder": "realistic_blend_xl_open_clip_vit_bigg14_f16.ckpt",
      "default_scale": 16
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1138590_redbluefantasy_fluxv10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Red_Blue_Fantasy_fluxv10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1445047_redcraftcadsupdatedjun1_f1fillnsfw_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "inpainting",
      "name": "Redcraft_CADSUpdated_JUN1_f1Fill_NSFW",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1315432_redcraftcadsupdatedjun1_newreveal_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_new_REVEAL",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1093373_redcraftcadsupdatedjun1_rasch1forge_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_rasch1Forge",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1115605_redcraftcadsupdatedjun1_rasch2_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_rasch2",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1344905_redcraftcadsupdatedjun1_rasch3rushreveal_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_rasch3RUSHReveal",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1550408_redcraftcadsupdatedjun1_realreveal5_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_realreveal5",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1745151_redcraftcadsupdatedjun1_redediticedit11_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "inpainting",
      "name": "Redcraft_CADSUpdated_JUN1_red_Edit_Icedit11",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1849802_redcraftcadsupdatedjun1_redomniflux1dreamo_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_red_OMNIFlux1Dreamo",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1087807_redcraftcadsupdatedjun1_revealnsfw_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_reveal_NSFW",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1171942_redcraftcadsupdatedjun1_revealultrav35_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_reveal_ULTRAV35",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1576605_redcraftcadsupdatedjun1_reveal5sfwultra_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_reveal5SFWULTRA",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1201074_redcraftcadsupdatedjun1_turborevealhotfix21_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Redcraft_CADSUpdated_JUN1_turbo_Reveal_Hotfix21",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "name": "RedCraft-CADS-UPdated-May4-Commercial-_-Advertising-Design-System",
      "upcast_attention": false,
      "clip_encoder": "redcraft___cads_updated_may4_commercial___advertising_design_system_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "text_encoder": "redcraft___cads_updated_may4_commercial___advertising_design_system_open_clip_vit_bigg14_f16.ckpt",
      "file": "redcraft___cads_updated_may4_commercial___advertising_design_system_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9",
      "default_scale": 16
    },
    {
      "file": "richyrichmixixl_f16.ckpt",
      "name": "richyrichMixIXL",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "text_encoder": "richyrichmixixl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "richyrichmixixl_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "upcast_attention": false,
      "version": "sdxl_base_v0.9"
    },
    {
      "name": "Rillusm-Realistic-IL",
      "modifier": "none",
      "clip_encoder": "rillusm___realistic_il_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "text_encoder": "rillusm___realistic_il_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false,
      "file": "rillusm___realistic_il_f16.ckpt",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "878315_sdvn11ghibliflux_fp8hyper_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Sdvn11Ghibli_Flux_fp8Hyper",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "prefix": "",
      "default_scale": 16,
      "file": "silvermoonmix_illustrious_evolved_f16.ckpt",
      "text_encoder": "silvermoonmix_illustrious_evolved_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "silvermoonmix_illustrious_evolved_clip_vit_l14_f16.ckpt",
      "upcast_attention": false,
      "name": "SilvermoonMix-Illustrious-Evolved"
    },
    {
      "text_encoder": "singlo_illustrious_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "clip_encoder": "singlo_illustrious_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "name": "SinGlo-illustrious",
      "file": "singlo_illustrious_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "modifier": "none"
    },
    {
      "clip_encoder": "skibidimix_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "SkibidiMix",
      "file": "skibidimix_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "version": "sdxl_base_v0.9",
      "text_encoder": "skibidimix_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false
    },
    {
      "prefix": "",
      "file": "smooth_mix_noobai_illustrious_pony_illustrious_v.2_1401686_f16.ckpt",
      "name": "Smooth_Mix_NoobAI_Illustrious_Pony_Illustrious_v.2_1401686",
      "upcast_attention": false,
      "default_scale": 16,
      "text_encoder": "smooth_mix_noobai_illustrious_pony_illustrious_v.2_1401686_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "smooth_mix_noobai_illustrious_pony_illustrious_v.2_1401686_clip_vit_l14_f16.ckpt"
    },
    {
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "upcast_attention": false,
      "text_encoder": "smooth_mix_noobai_illustrious_pony_illustrious_v.3_1470541_open_clip_vit_bigg14_f16.ckpt",
      "name": "Smooth_Mix_NoobAI_Illustrious_Pony_Illustrious_v.3_1470541",
      "file": "smooth_mix_noobai_illustrious_pony_illustrious_v.3_1470541_f16.ckpt",
      "clip_encoder": "smooth_mix_noobai_illustrious_pony_illustrious_v.3_1470541_clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Smooth_Mix_NoobAI_Illustrious_Pony_NoobAI_v2.0_1629718",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "smooth_mix_noobai_illustrious_pony_noobai_v2.0_1629718_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "file": "smooth_mix_noobai_illustrious_pony_noobai_v2.0_1629718_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "clip_encoder": "smooth_mix_noobai_illustrious_pony_noobai_v2.0_1629718_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "upcast_attention": false,
      "name": "Smooth_Mix_NoobAI_Illustrious_Pony_Pony_v.3_997031",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "text_encoder": "smooth_mix_noobai_illustrious_pony_pony_v.3_997031_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "file": "smooth_mix_noobai_illustrious_pony_pony_v.3_997031_f16.ckpt",
      "clip_encoder": "smooth_mix_noobai_illustrious_pony_pony_v.3_997031_clip_vit_l14_f16.ckpt"
    },
    {
      "name": "Smooth_Mix_NoobAI_Illustrious_Pony_Realism_1675843",
      "prefix": "",
      "modifier": "none",
      "text_encoder": "smooth_mix_noobai_illustrious_pony_realism_1675843_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "smooth_mix_noobai_illustrious_pony_realism_1675843_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "file": "smooth_mix_noobai_illustrious_pony_realism_1675843_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16
    },
    {
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "snowpony_open_clip_vit_bigg14_f16.ckpt",
      "name": "SnowPony",
      "modifier": "none",
      "file": "snowpony_f16.ckpt",
      "clip_encoder": "snowpony_clip_vit_l14_f16.ckpt",
      "default_scale": 16
    },
    {
      "default_scale": 16,
      "modifier": "none",
      "file": "steinillustrious_f16.ckpt",
      "text_encoder": "steinillustrious_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "clip_encoder": "steinillustrious_clip_vit_l14_f16.ckpt",
      "name": "SteinIllustrious"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "869391_stoiqonewrealityfluxsd35_f1dalpha_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Stoiqo_Newreality_FLUXSD35_F1DAlpha",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "979329_stoiqonewrealityfluxsd35_f1dalphatwo_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Stoiqo_Newreality_FLUXSD35_f1DAlpha_Two",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "897489_stoiqoafroditefluxxl_f1dalpha_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "STOIQOAfrodite_FLUXXL_F1DAlpha",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "742904_thearamintaexperiment_flux1a1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "The_Araminta_Experiment_flux1A1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "file": "throwing_pasta_mix_spaghetti_f16.ckpt",
      "clip_encoder": "throwing_pasta_mix_spaghetti_clip_vit_l14_f16.ckpt",
      "modifier": "none",
      "name": "Throwing-Pasta-MIX-Spaghetti",
      "text_encoder": "throwing_pasta_mix_spaghetti_open_clip_vit_bigg14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "default_scale": 16,
      "upcast_attention": false,
      "version": "sdxl_base_v0.9"
    },
    {
      "text_encoder": "toonify_toonify_illustrious_1495132_open_clip_vit_bigg14_f16.ckpt",
      "prefix": "",
      "name": "Toonify_Toonify_Illustrious_1495132",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "modifier": "none",
      "clip_encoder": "toonify_toonify_illustrious_1495132_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "toonify_toonify_illustrious_1495132_f16.ckpt",
      "version": "sdxl_base_v0.9"
    },
    {
      "modifier": "none",
      "file": "toonify_toonify_ponydiffusionxl_410539_f16.ckpt",
      "default_scale": 16,
      "upcast_attention": false,
      "clip_encoder": "toonify_toonify_ponydiffusionxl_410539_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "name": "Toonify_Toonify_PonyDiffusionXL_410539",
      "text_encoder": "toonify_toonify_ponydiffusionxl_410539_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "default_scale": 8,
      "upcast_attention": false,
      "file": "tt_animerge_f16.ckpt",
      "text_encoder": "tt_animerge_clip_vit_l14_f16.ckpt",
      "name": "tt-animerge",
      "version": "v1",
      "modifier": "none",
      "prefix": ""
    },
    {
      "name": "Ultra-Realistic-By-Stable-Yogi-Pony",
      "prefix": "",
      "file": "ultra_realistic_by_stable_yogi_pony_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "text_encoder": "ultra_realistic_by_stable_yogi_pony_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "clip_encoder": "ultra_realistic_by_stable_yogi_pony_clip_vit_l14_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1454015_ultrarealfinetune_v1_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ultrareal_Fine_Tune_v1",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1095703_ultrarealfinetune_v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ultrareal_Fine_Tune_v10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1164498_ultrarealfinetune_v20_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ultrareal_Fine_Tune_v20",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "1413133_ultrarealfinetune_v4_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Ultrareal_Fine_Tune_v4",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "upcast_attention": false,
      "clip_encoder": "umbroxponyxl_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "name": "UmbroxPonyXL",
      "prefix": "",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16,
      "file": "umbroxponyxl_f16.ckpt",
      "text_encoder": "umbroxponyxl_open_clip_vit_bigg14_f16.ckpt"
    },
    {
      "modifier": "none",
      "clip_encoder": "uncanny_valley_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "text_encoder": "uncanny_valley_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "name": "Uncanny-valley",
      "default_scale": 16,
      "upcast_attention": false,
      "file": "uncanny_valley_f16.ckpt"
    },
    {
      "modifier": "none",
      "version": "sdxl_base_v0.9",
      "default_scale": 16,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "file": "untitled_pony_f16.ckpt",
      "text_encoder": "untitled_pony_open_clip_vit_bigg14_f16.ckpt",
      "upcast_attention": false,
      "name": "untitled-pony",
      "clip_encoder": "untitled_pony_clip_vit_l14_f16.ckpt"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "988886_verusvision10b_10btransformer_q8p.ckpt",
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Verus_Vision10b_10b_Transformer",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "clip_encoder": "virtual_diffusion_pony_xl_2025_clip_vit_l14_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "text_encoder": "virtual_diffusion_pony_xl_2025_open_clip_vit_bigg14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "modifier": "none",
      "name": "Virtual-Diffusion-Pony-XL-2025",
      "file": "virtual_diffusion_pony_xl_2025_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "default_scale": 16
    },
    {
      "name": "Vixon_s-Dream-Weave",
      "upcast_attention": false,
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "text_encoder": "vixon_s_dream_weave_open_clip_vit_bigg14_f16.ckpt",
      "clip_encoder": "vixon_s_dream_weave_clip_vit_l14_f16.ckpt",
      "version": "sdxl_base_v0.9",
      "file": "vixons_dream_weave_f16.ckpt",
      "modifier": "none",
      "default_scale": 16,
      "prefix": ""
    },
    {
      "modifier": "none",
      "clip_encoder": "wai_shuffle_noob_clip_vit_l14_f16.ckpt",
      "text_encoder": "wai_shuffle_noob_open_clip_vit_bigg14_f16.ckpt",
      "name": "WAI-SHUFFLE-NOOB",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "default_scale": 16,
      "file": "wai_shuffle_noob_f16.ckpt",
      "prefix": "",
      "version": "sdxl_base_v0.9"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "862533_whiteflux1_v10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Whiteflux1_v10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "791130_xehentaianimeflux_03_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Xe_Hentai_Anime_FLUX_03",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "807911_xehentaianimeflux_04_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Xe_Hentai_Anime_FLUX_04",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "autoencoder": "flux_1_vae_f16.ckpt",
      "clip_encoder": "clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "file": "951641_xueronecyantencolor_fluxv10_q8p.ckpt",
      "guidance_embed": true,
      "high_precision_autoencoder": true,
      "hires_fix_scale": 24,
      "modifier": "none",
      "name": "Xuer_One_Cyan_Ten_Color_flux_V10",
      "noise_discretization": {
        "rf": {
          "_0": {
            "condition_scale": 1000,
            "sigma_max": 1,
            "sigma_min": 0
          }
        }
      },
      "objective": {
        "u": {
          "condition_scale": 1000
        }
      },
      "prefix": "",
      "text_encoder": "t5_xxl_encoder_q6p.ckpt",
      "upcast_attention": false,
      "version": "flux1"
    },
    {
      "text_encoder": "zavychromaxl_open_clip_vit_bigg14_f16.ckpt",
      "modifier": "none",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "upcast_attention": false,
      "version": "sdxl_base_v0.9",
      "prefix": "",
      "clip_encoder": "zavychromaxl_clip_vit_l14_f16.ckpt",
      "default_scale": 16,
      "name": "ZavyChromaXL",
      "file": "zavychromaxl_f16.ckpt"
    },
    {
      "modifier": "none",
      "default_scale": 16,
      "clip_encoder": "zep9_clip_vit_l14_f16.ckpt",
      "file": "zep9_f16.ckpt",
      "autoencoder": "sdxl_vae_v1.0_f16.ckpt",
      "prefix": "",
      "upcast_attention": false,
      "text_encoder": "zep9_open_clip_vit_bigg14_f16.ckpt",
      "name": "ZEP9",
      "version": "sdxl_base_v0.9"
    }
  ]
}
